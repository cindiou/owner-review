# 时间

```python
'''
Python 提供了一个 time 和 calendar 模块可以用于格式化日期和时间。

时间间隔是以秒为单位的浮点小数。
每个时间戳都以自从 1970 年 1 月 1 日午夜（历元）经过了多长时间来表示。
'''

time.time()	# 返回数值形式的时间戳

time.localtime() # 返回当地时间下的时间元组形式tupletime
	#  time.struct_time(tm_year=2016, tm_mon=4, tm_mday=7, tm_hour=10, tm_min=28, tm_sec=49, tm_wday=3, tm_yday=98, tm_isdst=0)
    
time.mktime(tupletime)  # 时间元组 => 时间戳

time.strftime(fmt[,tupletime])
	# 接收以时间元组，并返回以可读字符串表示的当地时间，格式由fmt决定。
time.strptime(str,fmt='%a %b %d %H:%M:%S %Y')
	# 根据fmt的格式把一个时间字符串解析为时间元组。

    
    
time.sleep(secs) # 休眠时间

# 只有连续调用的结果之间的差
time.perf_counter()
	# 返回计时器的精准时间（系统的运行时间），包含整个系统的睡眠时间
time.process_time()
	# 返回当前进程执行 CPU 的时间总和，不包含睡眠时间
```



```python
'''
%y 两位数的年份表示（00-99）
%Y 四位数的年份表示（000-9999）
%m 月份（01-12）
%d 月内中的一天（0-31）
%H 24小时制小时数（0-23）
%I 12小时制小时数（01-12）
%M 分钟数（00=59）
%S 秒（00-59）
%a 本地简化星期名称
%A 本地完整星期名称
%b 本地简化的月份名称
%B 本地完整的月份名称
%c 本地相应的日期表示和时间表示
%j 年内的一天（001-366）
%p 本地A.M.或P.M.的等价符
%U 一年中的星期数（00-53）星期天为星期的开始
%w 星期（0-6），星期天为星期的开始
%W 一年中的星期数（00-53）星期一为星期的开始
%x 本地相应的日期表示
%X 本地相应的时间表示
%Z 当前时区的名称
%% %号本身

'''
```





# 多线程

```python
# 每个独立的线程有一个程序运行的入口、顺序执行序列和程序的出口。
# 但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。
'''
Python3 线程中常用的两个模块为：
    _thread
    threading(推荐使用)
    
    _thread 提供了低级别的、原始的线程以及一个简单的锁，它相比于 threading 模块的功能还是比较有限的
'''
```





## _thread

```python
#!/usr/bin/python3

import _thread
import time

# 为线程定义一个函数
def print_time( threadName, delay):
   count = 0
   while count < 5:
      time.sleep(delay)
      count += 1
      print ("%s: %s" % ( threadName, time.ctime(time.time()) ))

# 创建两个线程
try:
   _thread.start_new_thread( print_time, ("Thread-1", 2, ) )
   _thread.start_new_thread( print_time, ("Thread-2", 4, ) )
except:
   print ("Error: 无法启动线程")

while 1:
   pass
```







## threading

```python
'''
threading.Thread

threading.currentThread(): 返回当前的线程变量。
threading.enumerate(): 返回一个包含正在运行的线程的list。正在运行指线程启动后、结束前，不包括启动前和终止后的线程。
threading.activeCount(): 返回正在运行的线程数量，与len(threading.enumerate())有相同的结果。

threading.Lock() # 线程同步,返回 锁对象，其具有acquire 方法和 release 方法
threading.Rlock()


threading.Thread实例 具有的方法:
    run(): 用以表示线程活动的方法。
    	# 继承threading.Thread 必须实现的抽象方法
    	
    start():启动线程活动。
    setDaemon(bool)：设置子线程为守护进程
    
    join([time]): 等待至线程中止。这阻塞调用线程直至线程的join() 方法被调用中止-正常退出或者抛出未处理的异常-或者是可选的超时发生。
    isAlive(): 返回线程是否活动的。
    getName(): 返回线程名。
    setName(): 设置线程名。
'''
```



### 内部类|threading.Thread

```javascript
class A{
    static class B{ // 错误；js中不可行，但可以该class B为function B，从而间接实现内部类的效果
        constructor(name){
            this.name=name
        }
        say(){
            console.log(`My name is ${this.name}`)
        }
    }
}
o=new A.B()
o.say()
```





```python
class A:
    class B:
        def __init__(self,name):
            self.name=name
    	def say(self):
            print(f"My name is {self.name}")
            
o=A.B("Jack")
o.say()
```





#### 直接使用

```python
1、使用元组传递 threading.Thread(target=方法名，args=（参数1,参数2, ...）)

import time
import threading

def song(a,b,c):
    print(a, b, c)
    for i in range(5):
        print("song")
        time.sleep(1)
if __name__ == "__main__":
    threading.Thread(target=song,args=(1,2,3)).start()
2、使用字典传递 threading.Thread(target=方法名, kwargs={"参数名": 参数1, "参数名": 参数2, ...})

threading.Thread(target=song,kwargs={"a":1,"c":3,"b":2}).start() #参数顺序可以变
3、混合使用元组和字典 threading.Thread(target=方法名，args=（参数1, 参数2, ...）, kwargs={"参数名": 参数1,"参数名": 参数2, ...})

threading.Thread(target=song,args=(1,),kwargs={"c":3,"b":2}).start()
```





#### 作为父类

```python
#!/usr/bin/python3

import threading
import time

class myThread (threading.Thread): # 继承threading.Thread类
    def __init__(self, threadID, name, delay):
        threading.Thread.__init__(self)
        self.threadID = threadID
        self.name = name
        self.delay = delay
        
    def run(self): # 必须实现 run方法
        print ("开启线程： " + self.name)
        # 获取锁，用于线程同步
        threadLock.acquire()
        print_time(self.name, self.delay, 3)
        # 释放锁，开启下一个线程
        threadLock.release()

def print_time(threadName, delay, counter):
    while counter:
        time.sleep(delay)
        print ("%s: %s" % (threadName, time.ctime(time.time())))
        counter -= 1

threadLock = threading.Lock()
threads = []

# 创建新线程
thread1 = myThread(1, "Thread-1", 1)
thread2 = myThread(2, "Thread-2", 2)

# 开启新线程
thread1.start()
thread2.start()

# 添加线程到线程列表
threads.append(thread1)
threads.append(thread2)

# 等待所有线程完成
for t in threads:
    t.join()
print ("退出主线程")
```





### join详解

```python
# https://www.cnblogs.com/cnkai/p/7504980.html

知识点一：
	当一个进程启动之后，会默认产生一个主线程，因为线程是程序执行流的最小单元，当设置多线程时，主线程会创建多个子线程，在python中，默认情况下（其实就是setDaemon(False)），主线程执行完自己的任务以后，就退出了，此时子线程会继续执行自己的任务，直到自己的任务结束，例子见下面一。

知识点二：
	当我们使用setDaemon(True)方法，设置子线程为守护线程时，主线程一旦执行结束，则全部线程全部被终止执行，可能出现的情况就是，子线程的任务还没有完全执行结束，就被迫停止，例子见下面二。

知识点三：
	此时join的作用就凸显出来了，join所完成的工作就是线程同步，即主线程任务结束之后，进入阻塞状态，一直等待其他的子线程执行结束之后，主线程在终止，例子见下面三。

    
知识点四：
	join有一个timeout参数：
    
	1.当设置守护线程时，含义是主线程对于子线程等待timeout的时间将会杀死该子线程，最后退出程序。所以说，如果有10个子线程，全部的等待时间就是每个timeout的累加和。简单的来说，就是给每个子线程一个timeout的时间，让他去执行，时间一到，不管任务有没有完成，直接杀死。
	2.没有设置守护线程时，主线程将会等待timeout的累加和这样的一段时间，时间一到，主线程结束，但是并没有杀死子线程，子线程依然可以继续执行，直到子线程全部结束，程序退出。
```





```python
import threading
import time

def run():

    time.sleep(2)
    print('当前线程的名字是： ', threading.current_thread().name)
    time.sleep(2)


if __name__ == '__main__':

    start_time = time.time()

    print('这是主线程：', threading.current_thread().name)
    thread_list = []
    for i in range(5):
        t = threading.Thread(target=run)
        thread_list.append(t)

    for t in thread_list:
        t.setDaemon(True) # 设置子线程为守护进程
        t.start()

    print('主线程结束了！' , threading.current_thread().name)
    print('一共用时：', time.time()-start_time)
    
'''打印结果：
这是主线程：MainThread
主线程结束了！ MainThread
一共用时: 0.00000135426
'''
```





## 队列queue

```python
'''
# 为什么需要队列？
	因为队列是线程安全的，不会破坏代码的原子性

# 分类
	FIFO（先入先出)队列Queue
	LIFO（后入先出）队列LifoQueue
	优先级队列 PriorityQueue
	双端队列 deque
'''
Queue.queue
Queue.qsize() 返回队列的大小
Queue.empty() 如果队列为空，返回True,反之False
Queue.full() 如果队列满了，返回True,反之False
Queue.full 与 maxsize 大小对应
Queue.get([block[, timeout]])获取队列，timeout等待时间
Queue.get_nowait() 相当Queue.get(False)
Queue.put(item) 写入队列，timeout等待时间
Queue.put_nowait(item) 相当Queue.put(item, False)


# 解析：https://blog.csdn.net/sjyttkl/article/details/79887720
Queue.task_done() 在完成一项工作之后，Queue.task_done()函数向任务已经完成的队列发送一个信号。每个get()调用得到一个任务，接下来的task_done()告诉队列该任务已经处理完毕
	# 主要是给join用的，每次get后需要调用task_done，直到所有任务都task_done。join才取消阻塞
    
Queue.join() 实际上意味着等到队列为空，再执行别的操作
```



```python
from queue import Queue,LifoQueue,PriorityQueue		#，deque
q=Queue(3)
lq=LifoQueue(4)
pq=PriorityQueue(5)

for i in range(3):
    q.put(i)
    lq.put(i)
    pq.put(i)
    
print(f"先进先出队列:\n\tqueue:{q.queue}\n\tsize:{q.qsize()}\n\tisFull:{q.full()}")
print(f"先进后出队列:\n\tqueue:{lq.queue}\n\tsize:{lq.qsize()}\n\tisFull:{lq.full()}")
print(f"优先队列:\n\tqueue:{pq.queue}\n\tsize:{pq.qsize()}\n\tisFull:{pq.full()}")

'''
先进先出队列:
	queue:deque([0, 1, 2])
	size:3
	isFull:True
先进后出队列:
	queue:[0, 1, 2]
	size:3
	isFull:False
优先队列:
	queue:[0, 1, 2]
	size:3
	isFull:False
'''
```





```python
#!/usr/bin/python3

import queue
import threading
import time

exitFlag = 0

class myThread (threading.Thread):
    def __init__(self, threadID, name, q):
        threading.Thread.__init__(self)
        self.threadID = threadID
        self.name = name
        self.q = q
    def run(self):
        print ("开启线程：" + self.name)
        process_data(self.name, self.q)
        print ("退出线程：" + self.name)

def process_data(threadName, q):
    while not exitFlag:
        queueLock.acquire()
        if not workQueue.empty():
            data = q.get()
            queueLock.release()
            print ("%s processing %s" % (threadName, data))
        else:
            queueLock.release()
        time.sleep(1)

threadList = ["Thread-1", "Thread-2", "Thread-3"]
nameList = ["One", "Two", "Three", "Four", "Five"]
queueLock = threading.Lock()
workQueue = queue.Queue(10)
threads = []
threadID = 1

# 创建新线程
for tName in threadList:
    thread = myThread(threadID, tName, workQueue)
    thread.start()
    threads.append(thread)
    threadID += 1

# 填充队列
queueLock.acquire()
for word in nameList:
    workQueue.put(word)
queueLock.release()

# 等待队列清空
while not workQueue.empty():
    pass

# 通知线程是时候退出
exitFlag = 1

# 等待所有线程完成
for t in threads:
    t.join()
print ("退出主线程")
```







# urllib

```python
'''
urllib.request - 打开和读取 URL。
urllib.error - 包含 urllib.request 抛出的异常。
urllib.parse - 解析 URL。
urllib.robotparser - 解析 robots.txt 文件。

'''

from urllib.request import urlopen,Request,quote,unquote

	urlopen(url, data=None, [timeout, ]*, cafile=None, capath=None, cadefault=False, context=None)
url：url 地址。
        '''
        data：发送到服务器的其他数据对象，默认为 None。
        timeout：设置访问超时时间。
        cafile 和 capath：cafile 为 CA 证书， capath 为 CA 证书的路径，使用 HTTPS 需要用到。
        cadefault：已经被弃用。
        context：ssl.SSLContext类型，用来指定 SSL 设置。
        '''
    
    	read、readline、readlines
      
    Request(url, data=None, headers={}, origin_req_host=None, unverifiable=False, method=None)
        '''
        url：url 地址。
        data：发送到服务器的其他数据对象，默认为 None。
        headers：HTTP 请求的头部信息，字典格式。
        origin_req_host：请求的主机地址，IP 或域名。
        unverifiable：很少用整个参数，用于设置网页是否需要验证，默认是False。。
        method：请求方法， 如 GET、POST、DELETE、PUT等。   
        ''' 
    
    
    
from urllib.parse import urlencode,urlparse




from urllib.error import URLError,HTTPError
	属性 code 为 HTTP 的状态码
    reason 为引发异常的原因
    headers 为导致 HTTPError 的特定 HTTP 请求的 HTTP 响应头。
```





## request.urlopen

```python
import urllib.request

myURL1 = urllib.request.urlopen("https://www.runoob.com/")
print(myURL1.getcode())   # 200

try:
    myURL2 = urllib.request.urlopen("https://www.runoob.com/no.html")
except urllib.error.HTTPError as e:
    if e.code == 404:
        print(404)   # 404
```





## request.Request

```python
import urllib.request
import urllib.parse

url = 'https://www.runoob.com/try/py3/py3_urllib_test.php'  # 提交到表单页面
data = {'name':'RUNOOB', 'tag' : '菜鸟教程'}   # 提交数据
header = {
    'User-Agent':'Mozilla/5.0 (X11; Fedora; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'
}   #头部信息
data = urllib.parse.urlencode(data).encode('utf8')  # 对参数进行编码，解码使用 urllib.parse.urldecode
request=urllib.request.Request(url, data, header)   # 请求处理
reponse=urllib.request.urlopen(request).read()      # 读取结果

fh = open("./urllib_test_post_runoob.html","wb")    # 将文件写入到当前目录中
fh.write(reponse)
fh.close()
```



## parse.urlparse

```python
from urllib.parse import urlparse

o = urlparse("https://www.runoob.com/?s=python+%E6%95%99%E7%A8%8B")
print(o) # 字典

'''
以上实例输出结果为：
	ParseResult(scheme='https', netloc='www.runoob.com', path='/', params='', query='s=python+%E6%95%99%E7%A8%8B', fragment='')
'''
```







# 爬虫

## BeautifulSoup4

```python
# pip3 install beautifulsoup4
# pip3 install xml
'''Beautiful Soup支持Python标准库中的HTML解析器,还支持一些第三方的解析器，如果我们不安装它，则 Python 会使用 Python默认的解析器，lxml 解析器更加强大，速度更快，推荐安装。
'''


from urllib.request import urlopen
from bs4 import BeautifulSoup
url="http://baidu.com/"
html_doc=urlopen(url).read().decode("utf-8")

# BeautifulSoup(html_doc,"html.parser")
'''soup 等价于 document'''
soup=BeautifulSoup(html_doc,features="lxml")


#=================================================
# soup.get_text() == html_doc
# 获取<body>标签中的第一个<b>标签:
soup.body.b

# print(type(soup.title))
# <class 'bs4.element.Tag'>
'''元素节点'''
element=soup.title
element.name
element["class"]
	# element.get("class")
element.attrs

# 例如：
element['class'] = 'verybold'
element['id'] = 1
element
# <blockquote class="verybold" id="1">Extremely bold</blockquote>

# 也可以删除 属性节点
del tag['class']
del tag['id']


```





### 搜索文档树

#### find_all

```python
'''
1、用法
2、获取标签的名称
3、获取标签的属性
4、获取标签的内容
5、嵌套选择
6、子节点、子孙节点
7、父节点、祖先节点
8、兄弟节点
'''

#==========================标签选择器=============================
#1、五种过滤器: 字符串、正则表达式、列表、True、方法
#1.1、字符串：即标签名
print(soup.find_all('b'))

#1.2、正则表达式
import re
print(soup.find_all(re.compile('^b'))) #找出b开头的标签，结果有body和b标签

#1.3、列表：如果传入列表参数,Beautiful Soup会将与列表中任一元素匹配的内容返回.下面代码找到文档中所有<a>标签和<b>标签:
print(soup.find_all(['a','b']))

#1.4、True：可以匹配任何值,下面代码查找到所有的tag,但是不会返回字符串节点
print(soup.find_all(True))
for tag in soup.find_all(True):
    print(tag.name)

#1.5、方法:如果没有合适过滤器,那么还可以定义一个方法,方法只接受一个元素参数 ,如果这个方法返回 True 表示当前元素匹配并且被找到,如果不是则反回 False
def has_class_but_no_id(tag):
    return tag.has_attr('class') and not tag.has_attr('id')

print(soup.find_all(has_class_but_no_id))


#==========================属性选择器=============================
#2、find_all( name , attrs , recursive , text , **kwargs )
#2.1、name: 搜索name参数的值可以使任一类型的 过滤器 ,字符窜,正则表达式,列表,方法或是 True .
print(soup.find_all(name=re.compile('^t')))

#2.2、keyword: key=value的形式，value可以是过滤器：字符串 , 正则表达式 , 列表, True .
print(soup.find_all(id=re.compile('my')))
print(soup.find_all(href=re.compile('lacie'),id=re.compile('\d'))) #注意类要用class_
print(soup.find_all(id=True)) #查找有id属性的标签

# 有些tag属性在搜索不能使用,比如HTML5中的 data-* 属性:
data_soup = BeautifulSoup('<div data-foo="value">foo!</div>','lxml')
# data_soup.find_all(data-foo="value") #报错：SyntaxError: keyword can't be an expression
# 但是可以通过 find_all() 方法的 attrs 参数定义一个字典参数来搜索包含特殊属性的tag:
print(data_soup.find_all(attrs={"data-foo": "value"}))
# [<div data-foo="value">foo!</div>]

#2.3、按照类名查找，注意关键字是class_，class_=value,value可以是五种选择器之一
print(soup.find_all('a',class_='sister')) #查找类为sister的a标签
print(soup.find_all('a',class_='sister ssss')) #查找类为sister和sss的a标签，顺序错误也匹配不成功
print(soup.find_all(class_=re.compile('^sis'))) #查找类为sister的所有标签

#2.4、attrs
print(soup.find_all('p',attrs={'class':'story'}))
soup.find_all(attrs={'src':re.compile(r'(.*?)\.(jpg|jpeg|png|gif)')}
soup.find_all('a',attrs={'href':re.compile(r'https://mofan')}
              
#2.5、text: 值可以是：字符，列表，True，正则
print(soup.find_all(text='Elsie'))
print(soup.find_all('a',text='Elsie'))

#2.6、limit参数:如果文档树很大那么搜索会很慢.如果我们不需要全部结果,可以使用 limit 参数限制返回结果的数量.效果与SQL中的limit关键字类似,当搜索到的结果数量达到 limit 的限制时,就停止搜索返回结果
print(soup.find_all('a',limit=2))

#2.7、recursive:调用tag的 find_all() 方法时,Beautiful Soup会检索当前tag的所有子孙节点,如果只想搜索tag的直接子节点,可以使用参数 recursive=False .
print(soup.html.find_all('a'))
print(soup.html.find_all('a',recursive=False))



'''
像调用 find_all() 一样调用tag
find_all() 几乎是Beautiful Soup中最常用的搜索方法,所以我们定义了它的简写方法. BeautifulSoup 对象和 tag 对象可以被当作一个方法来使用,这个方法的执行结果与调用这个对象的 find_all() 方法相同,下面两行代码是等价的:
soup.find_all("a")
soup("a")
这两行代码也是等价的:
soup.title.find_all(text=True)
soup.title(text=True)
'''
```



#### find

```python
#3、find( name , attrs , recursive , text , **kwargs )
find_all() 方法将返回文档中符合条件的所有tag,尽管有时候我们只想得到一个结果.比如文档中只有一个<body>标签,那么使用 find_all() 方法来查找<body>标签就不太合适, 使用 find_all 方法并设置 limit=1 参数不如直接使用 find() 方法.下面两行代码是等价的:

soup.find_all('title', limit=1)
# [<title>The Dormouse's story</title>]
soup.find('title')
# <title>The Dormouse's story</title>

唯一的区别是 find_all() 方法的返回结果是值包含一个元素的列表,而 find() 方法直接返回结果.
find_all() 方法没有找到目标是返回空列表, find() 方法找不到目标时,返回 None .
print(soup.find("nosuchtag"))
# None

soup.head.title 是 tag的名字 方法的简写.这个简写的原理就是多次调用当前tag的 find() 方法:

soup.head.title
# <title>The Dormouse's story</title>
soup.find("head").find("title")
# <title>The Dormouse's story</title>
```





#### select

```python
（1）通过标签名查找

print(soup.select("title"))  #[<title>The Dormouse's story</title>]
print(soup.select("b"))      #[<b>The Dormouse's story</b>]

（2）通过类名查找

print(soup.select(".sister")) 

'''
[<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>, 
<a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>, 
<a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]

'''

（3）通过 id 名查找

print(soup.select("#link1"))
# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>]

（4）组合查找

组合查找即和写 class 文件时，标签名与类名、id名进行的组合原理是一样的，例如查找 p 标签中，id 等于 link1的内容，二者需要用空格分开

print(soup.select("p #link2"))

#[<a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>]

直接子标签查找

print(soup.select("p > #link2"))
# [<a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>]

（5）属性查找

查找时还可以加入属性元素，属性需要用中括号括起来，注意属性和标签属于同一节点，所以中间不能加空格，否则会无法匹配到。

print(soup.select("a[href='http://example.com/tillie']"))
#[<a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]

select 方法返回的结果都是列表形式，可以遍历形式输出，然后用 get_text() 方法来获取它的内容：
复制代码
```





## Xpath

```markdown
# https://www.runoob.com/xpath/xpath-syntax.html
# https://www.cnblogs.com/long4275/p/15695243.html
```

```xml
<?xml version="1.0" encoding="UTF-8"?>
 
<bookstore>
    <book>
      <title lang="eng">Harry Potter</title>
      <price>29.99</price>
    </book>

    <book>
      <title lang="eng">Learning XML</title>
      <price>39.95</price>
    </book>
</bookstore>
```







| 表达式   | 描述                                                         |
| -------- | ------------------------------------------------------------ |
| nodename | 选取此节点的所有子节点。                                     |
| /        | 从根节点选取（取子节点）。                                   |
| //       | 从匹配选择的当前节点选择文档中的节点，而不考虑它们的位置（取子孙节点）。 |
| .        | 选取当前节点。                                               |
| ..       | 选取当前节点的父节点。                                       |
| @        | 选取属性。                                                   |

| 路径表达式                          | 结果                                                         |
| ----------------------------------- | ------------------------------------------------------------ |
| /bookstore/book[1]                  | 选取属于 bookstore 子元素的第一个 book 元素。                |
| /bookstore/book[last()]             | 选取属于 bookstore 子元素的最后一个 book 元素。              |
| /bookstore/book[last()-1]           | 选取属于 bookstore 子元素的倒数第二个 book 元素。            |
| /bookstore/book[position()<3]       | 选取最前面的两个属于 bookstore 元素的子元素的 book 元素。    |
| //title[@lang]                      | 选取所有拥有名为 lang 的属性的 title 元素。                  |
| //title[@lang='eng']                | 选取所有 title 元素，且这些元素拥有值为 eng 的 lang 属性。   |
| /bookstore/book[price>35.00]        | 选取 bookstore 元素的所有 book 元素，且其中的 price 元素的值须大于 35.00。 |
| /bookstore/book[price>35.00]//title | 选取 bookstore 元素中的 book 元素的所有 title 元素，且其中的 price 元素的值须大于 35.00。 |






| 通配符 | 描述                 |
| ------ | -------------------- |
| *      | 匹配任何元素节点。   |
| @*     | 匹配任何属性节点。   |
| node() | 匹配任何类型的节点。 |


| 路径表达式   | 结果                              |
| ------------ | --------------------------------- |
| /bookstore/* | 选取 bookstore 元素的所有子元素。 |
| //*          | 选取文档中的所有元素。            |
| //title[@*]  | 选取所有带有属性的 title 元素。   |





| 路径表达式                       | 结果                                                         |
| -------------------------------- | ------------------------------------------------------------ |
| //book/title \| //book/price     | 选取 book 元素的所有 title 和 price 元素。                   |
| //title \| //price               | 选取文档中的所有 title 和 price 元素。                       |
| /bookstore/book/title \| //price | 选取属于 bookstore 元素的 book 元素的所有 title 元素，以及文档中所有的 price 元素。 |






```python
# from lxml import etree
selector=etree.HTML(源码) #将源码转化为能被XPath匹配的格式
selector.xpath(表达式) #返回为一列表


ret=selector.xpath("//div")
ret=selector.xpath("/div")
ret=selector.xpath("./div")
ret=selector.xpath("//p[@id='p1']")
ret=selector.xpath("//div[@class='d1']/div/p[@class='story']")

```



```python

五、Xpath轴
轴可以定义相对于当前节点的节点集

轴名称                      表达式                                  描述
ancestor                xpath(‘./ancestor::*’)              选取当前节点的所有先辈节点（父、祖父）
ancestor-or-self        xpath(‘./ancestor-or-self::*’)      选取当前节点的所有先辈节点以及节点本身
attribute               xpath(‘./attribute::*’)             选取当前节点的所有属性
child                   xpath(‘./child::*’)                 返回当前节点的所有子节点
descendant              xpath(‘./descendant::*’)            返回当前节点的所有后代节点（子节点、孙节点）
following               xpath(‘./following::*’)             选取文档中当前节点结束标签后的所有节点
following-sibing        xpath(‘./following-sibing::*’)      选取当前节点之后的兄弟节点
parent                  xpath(‘./parent::*’)                选取当前节点的父节点
preceding               xpath(‘./preceding::*’)             选取文档中当前节点开始标签前的所有节点

preceding-sibling       xpath(‘./preceding-sibling::*’)     选取当前节点之前的兄弟节点
self                    xpath(‘./self::*’)                  选取当前节点
 

六、功能函数   
使用功能函数能够更好的进行模糊搜索

函数                  用法                                                               解释
starts-with         xpath(‘//div[starts-with(@id,”ma”)]‘)                        选取id值以ma开头的div节点
contains            xpath(‘//div[contains(@id,”ma”)]‘)                           选取id值包含ma的div节点
and                 xpath(‘//div[contains(@id,”ma”) and contains(@id,”in”)]‘)    选取id值包含ma和in的div节点
text()              xpath(‘//div[contains(text(),”ma”)]‘)                        选取节点文本包含ma的div节点



'''
Element对象

class xml.etree.ElementTree.Element(tag, attrib={}, **extra)

　　tag：string，元素代表的数据种类。
　　text：string，元素的内容。
　　tail：string，元素的尾形。
　　attrib：dictionary，元素的属性字典。
　　
　　＃针对属性的操作
　　clear()：清空元素的后代、属性、text和tail也设置为None。
　　get(key, default=None)：获取key对应的属性值，如该属性不存在则返回default值。
　　items()：根据属性字典返回一个列表，列表元素为(key, value）。
　　keys()：返回包含所有元素属性键的列表。
　　set(key, value)：设置新的属性键与值。

　　＃针对后代的操作
　　append(subelement)：添加直系子元素。
　　extend(subelements)：增加一串元素对象作为子元素。＃python2.7新特性
　　find(match)：寻找第一个匹配子元素，匹配对象可以为tag或path。
　　findall(match)：寻找所有匹配子元素，匹配对象可以为tag或path。
　　findtext(match)：寻找第一个匹配子元素，返回其text值。匹配对象可以为tag或path。
　　insert(index, element)：在指定位置插入子元素。
　　iter(tag=None)：生成遍历当前元素所有后代或者给定tag的后代的迭代器。＃python2.7新特性
　　iterfind(match)：根据tag或path查找所有的后代。
　　itertext()：遍历所有后代并返回text值。
　　remove(subelement)：删除子元素。



'''
```









## Requests

```python
import requests
import webbrowser
params={"wd":"火影忍者"}
r=requests.get("https://www.baidu.com",params=params)
webbrowser.open(r.url)

# r.text	返回内容
	# r.content	二进制内容
# r.status_code
# r.url
# r.encoding	查看编码
#  r.json()
# r.headers['Content-Type']
	# r.request.headers
# r.cookies['ts']

# params	data 	json 	cookies		files
# headers proxies



# ==========================================
#设置访问代理
proxies = {
           "http": "http://10.10.1.10:3128",
           "https": "http://10.10.1.100:4444",
          }
r = requests.get('http://m.ctrip.com', proxies=proxies)


#如果代理需要用户名和密码，则需要这样：
proxies = {
    "http": "http://user:pass@10.10.1.10:3128/",
}


# ==========================================
# 要在请求中传入Cookie，只需准备一个dict传入cookies参数：
# 登入
cs = {'token': '12345', 'status': 'working'}
r = requests.get(url, cookies=cs)

session=requests.Session()
post_url=""
get_url=""
payload={}
r=session.post(url,data=payload)
print(r.cookies.get_dict())

r=session.get(get_url)
print(r.text)

# ==========================================
# 下载
from urllib.request import urlretrieve
download_url=""
save_path="./img/123456.png"
urlretrieve(download_url,save_path)

# 方式二
import requests
r=request.get(download_url)
with open(save_path,'wb') as f:
    f.write(r.content)
    

# 方式三:存储大型文件，比如：电影
r=requests.get(download_url,stream=True)
while open(save_path,'wb') as f:
    for chunk in r.iter_content(chunk_size=32):
        f.write(chunk)
    
    
# ==========================================
# requests默认使用application/x-www-form-urlencoded对POST数据编码。如果要传递JSON数据，可以直接传入json参数：
# 传入data参数作为POST请求的数据

# 上传JSON数据
params = {'key': 'value'}
r = requests.post(url, json=params) # 内部自动序列化为JSON

# 上传文件需要更复杂的编码格式，但是requests把它简化成files参数
upload_files = {'file': open('report.xls', 'rb')}
r = requests.post(url, files=upload_files)


# ==========================================
# 要指定超时，传入以秒为单位的timeout参数：
r = requests.get(url, timeout=2.5) # 2.5秒后超时
```





## 异步







## Scripy
