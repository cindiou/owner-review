# 面向对象编程

```python
# 1.可以自由地给一个实例变量绑定属性，比如，给实例bart绑定一个name属性：
>>> bart.name = 'Bart Simpson'


# 2,。在类中定义的函数只有一点不同，就是第一个参数永远是实例变量self，并且，调用时，不用传递该参数


# 3.数据封装：存储器属性 get 和 set
	可以对参数做检查，避免传入无效的参数：
# 在Python中，实例的变量名如果以__开头，就变成了一个私有变量（private），只有内部可以访问，外部不能访问
	不能直接访问__name是因为Python解释器对外把__name变量改成了_Student__name
# 在Python中，变量名类似__xxx__的，也就是以双下划线开头，并且以双下划线结尾的，是特殊变量，特殊变量是可以直接访问的，不是private变量
>> bart = Student('Bart Simpson', 59)
>>> bart.get_name()
'Bart Simpson'
>>> bart.__name = 'New Name' # 设置__name变量！
>>> bart.__name
'New Name'
表面上看，外部代码“成功”地设置了__name变量，但实际上这个__name变量和class内部的__name变量不是一个变量！内部的__name变量已经被Python解释器自动改成了_Student__name，而外部代码给bart新增了一个__name变量



# 4.继承，多态
# 动态类型语言 -> 鸭子类型
不一定需要传入Animal类型。我们只需要保证传入的对象有一个run()方法就可以了：



# 5. type 和 isinstance 和 issubclass
# getattr 、 hasattr 、 setattr 、 delattr
判断基本数据类型可以直接写int，str等，但如果要判断一个对象是否是函数怎么办？可以使用types模块中定义的常量：
    '''
    >>> import types
    >>> def fn():
    ...     pass
    ...
    >>> type(fn)==types.FunctionType
    True
    >>> type(abs)==types.BuiltinFunctionType
    True
    >>> type(lambda x: x)==types.LambdaType
    True
    >>> type((x for x in range(10)))==types.GeneratorType
    True
    '''
    
判断一个变量是否是某些类型中的一种;优先使用isinstance()判断类型，可以将指定类型及其子类“一网打尽”
    '''
    >>> isinstance([1, 2, 3], (list, tuple))
    True
    >>> isinstance((1, 2, 3), (list, tuple))
    True
     '''
    
    
# 6.直接在class中定义属性，这种属性是类属性，归Student类所有：
class Student(object):
    name = 'Student'
    
实例属性属于各个实例所有，互不干扰；
类属性属于类所有，所有实例共享一个属性；
千万不要对实例属性和类属性使用相同的名字，因为相同名称的实例属性将屏蔽掉类属性，但是当你删除实例属性后，再使用相同的名称，访问到的将是类属性。


# 7.通过多重继承，一个子类就可以同时获得多个父类的所有功能。
	不需要复杂而庞大的继承链，只要选择组合不同的类的功能，就可以快速构造出所需的子类
```





## `__slots__`

```python
__slots__ 限制 实例 动态绑定的成员
	'''使用__slots__要注意，__slots__定义的属性仅对当前类实例起作用，对继承的子类是不起作用的：'''
	限制 属性
    限制 方法
    	MethodType动态绑定 类似 JS中的bind
        
    class Student(object):
        # 用tuple定义允许绑定的属性名称   
        # Student的实例对象 仅允许动态绑定 属性name、age
        __slots__ = ('name', 'age')      

但是，给一个实例绑定的方法，对另一个实例是不起作用的：
    >>> from types import MethodType
    >>> def set_age(self, age): # 定义一个函数作为实例方法
    ...     self.age = age
    ...
    >>> s.set_age = MethodType(set_age, s) # 给实例绑定一个方法
    >>> s.set_age(25) # 调用实例方法
    >>> s.age # 测试结果
    
为了给所有实例都绑定方法，可以给class绑定方法：
    >>> def set_score(self, score):
    ...     self.score = score
    ...
    >>> Student.set_score = set_score
```





```python
from types import MethodType


class Student(object):
    def __init__(self, *args, **kwargs):
        self.name = kwargs.pop('name')
        self.age = kwargs.pop('age')
        self.score = kwargs.pop('score')


def set_score(self, value):
    # 这里的MethodType绑定之后 类似于 @classmethod
    # 即:这里的self 实际上是 cls
    self.score = value


def get_score(self):
    return self.score


Student.set_score = MethodType(set_score, Student)
Student.get_score = MethodType(get_score, Student)
t = Student(name="Bryan", age=24, score=80)
# 输出80
print(t.score)
t.set_score(100)
# 输出100
print(t.get_score())
# 为什么这里还是输出80，而不是100？
print(t.score)
```







## `@property`

```python
所有在他们的程序中使用了我们先前类的客户都必须更改他们的代码：obj.temperature改为obj.get_temperature()，所有的赋值语句也必须更改，比如obj.temperature = val改为obj.set_temperature(val)。这样的重构会给那些拥有成千上万行代码的客户带来很大的麻烦。

总而言之，我们的更新是不'向后兼容'地。这就是需要property闪亮登场的地方。

# property(fget=None, fset=None, fdel=None, doc=None)
class Celsius:
    def __init__(self, temperature = 0):
        self.temperature = temperature
 
    def to_fahrenheit(self):
        return (self.temperature * 1.8) + 32
 
    def get_temperature(self):
        print("Getting value")
        return self._temperature
 
    def set_temperature(self, value):
        if value < -273:
            raise ValueError("Temperature below -273 is not possible")
        print("Setting value")
        self._temperature = value
 
    temperature = property(get_temperature,set_temperature)
    
    
    # ===============================================
    class Celsius:
    def __init__(self, temperature = 0):
        self._temperature = temperature
 
    def to_fahrenheit(self):
        return (self.temperature * 1.8) + 32
 
    @property
    def temperature(self):
        print("Getting value")
        return self._temperature
 
    @temperature.setter
    def temperature(self, value):
        if value < -273:
            raise ValueError("Temperature below -273 is not possible")
        print("Setting value")
        self._temperature = value
```





### 注意事项

```python
属性的方法名不要和实例变量重名。例如，以下的代码是错误的：

class Student(object):

    # 方法名称和实例变量均为birth:
    @property
    def birth(self):
        return self.birth
这是因为调用s.birth时，首先转换为方法调用，在执行return self.birth时，又视为访问self的属性，于是又转换为方法调用，造成无限递归，最终导致栈溢出报错RecursionError。
```







### `__get__` 、 `__getattr__`与`__getattribute__`

```python
# https://blog.csdn.net/Leafage_M/article/details/54960432
# https://www.cnblogs.com/flashboxer/p/9771797.html
__get__ | __set__ | __delete__
# 描述类

属性可以分为两类
	一类是Python自动产生的，如__class__，__hash__等
    另一类是我们自定义的，如上面的hello，name。我们只关心自定义属性。
    
类和实例对象(实际上，Python中一切都是对象，类是type的实例)都有__dict__属性，里面存放它们的自定义属性(对与类，里面还存放了别的东西)
	有些内建类型，如list和string，它们没有__dict__属性，随意没办法在它们上面附加自定义属性

'''
只有在类的__dict__中找到属性，Python才会去看看它有没有__get__等方法，对一个在实例的__dict__中找到的属性，Python根本不理会它有没有__get__等方法，直接返回属性本身

如果直接通过类访问descriptor，obj是None，此时type就是类本身
	1.读取属性时，如T.d,返回的是d.__get__(None, T)的结果;
	  t.d返回的是d.__get__(t, T)的结果。
	2.设置属性时，t.d = value，实际上调用d.__set__(t, value); 
	  T.d = value，这是真正的赋值，T.d的值从此变成value
'''
# ===============================================
class Descriptor(object):  
    def __get__(self, obj, type=None):  
            return 'get', self, obj, type  
    def __set__(self, obj, val):  
        print 'set', self, obj, val  
    def __delete__(self, obj):  
        print 'delete', self, obj  

class T(object):  
    d = Descriptor()  
t = T()  
```





#### 区别

```python
# https://www.cnblogs.com/huchong/p/9306459.html


每次通过实例访问属性，都会经过__getattribute__函数。
而当属性不存在时，仍然需要访问__getattribute__，不过接着要访问__getattr__。这就好像是一个异常处理函数。 

每次访问descriptor（即实现了__get__的类），都会先经过__get__函数。 

需要注意的是，当使用类访问不存在的变量是，不会经过__getattr__函数。
	# 要看 类的父类（或者元类？）中 是否存在 __getattr__
而descriptor不存在此问题，只是把instance标识为none而已。
```



```python
class C(object):
    a = 'abc'

    def __getattribute__(self, name):
        print("__getattribute__() is called"),name
        return object.__getattribute__(self, name)

    def __getattr__(self, name):
        print("__getattr__() is called "),name
        return name + " from getattr"

    def __get__(self, instance, owner):
        print("__get__() is called", instance, owner)
        return self

    def foo(self, x):
        print(x)


class C2(object):
    d = C()


if __name__ == '__main__':
    c = C()
    c2 = C2()
    print(c.a)
    print(c.zzzzzzzz)
    print '==============1'
    C2.d
    print '==============2'
    print(c2.d.a)
    
'''
结果：
    __getattribute__() is called a
    abc
    __getattribute__() is called zzzzzzzz
    __getattr__() is called  zzzzzzzz
    zzzzzzzz from getattr
    ==============1
    ('__get__() is called', None, <class '__main__.C2'>)
    ==============2
    ('__get__() is called', <__main__.C2 object at 0x00000000030BCDA0>, <class '__main__.C2'>)
    __getattribute__() is called a
    abc
'''
```











### 实现

```python
class Property:
    "Emulate PyProperty_Type() in Objects/descrobject.c"

    def __init__(self, fget=None, fset=None, fdel=None, doc=None):
        self.fget = fget
        self.fset = fset
        self.fdel = fdel
        if doc is None and fget is not None:
            doc = fget.__doc__
        self.__doc__ = doc

    def __get__(self, obj, objtype=None):
        if obj is None:
            # <property object at 0x7f1cf7b73450>
            return self
        if self.fget is None:
            raise AttributeError("unreadable attribute")
        return self.fget(obj)

    def __set__(self, obj, value):
        if self.fset is None:
            raise AttributeError("can't set attribute")
        self.fset(obj, value)

    def __delete__(self, obj):
        if self.fdel is None:
            raise AttributeError("can't delete attribute")
        self.fdel(obj)

    def getter(self, fget):
        return type(self)(fget, self.fset, self.fdel, self.__doc__)

    def setter(self, fset):
        return type(self)(self.fget, fset, self.fdel, self.__doc__)

    def deleter(self, fdel):
        return type(self)(self.fget, self.fset, fdel, self.__doc__)
```







## 定制API

```python
__slots__
__len__

__str__
__repr__
class Student(object):
    def __init__(self, name):
        self.name = name
    def __str__(self):
        return 'Student object (name=%s)' % self.name
    __repr__ = __str__
```



```python
__iter__
__next__
__getitem__
	'''
		传入的参数可能是一个int，也可能是一个切片对象slice，所以要做判断
			下列案列中 没有对step参数作处理；也没有对负数作处理
		此外，如果把对象看成dict，__getitem__()的参数也可能是一个可以作key的object
	'''
__setitem__
__delitem__

class Fib(object):
    def __init__(self):
        self.a, self.b = 0, 1 # 初始化两个计数器a，b

    def __iter__(self):
        return self # 实例本身就是迭代对象，故返回自己

    def __next__(self):
        self.a, self.b = self.b, self.a + self.b # 计算下一个值
        if self.a > 100000: # 退出循环的条件
            raise StopIteration()
        return self.a # 返回下一个值
    
    def __getitem__(self, n):
        if isinstance(n, int): # n是索引
            a, b = 1, 1
            for x in range(n):
                a, b = b, a + b
            return a
        if isinstance(n, slice): # n是切片
            start = n.start
            stop = n.stop
            if start is None:
                start = 0
            a, b = 1, 1
            L = []
            for x in range(stop):
                if x >= start:
                    L.append(a)
                a, b = b, a + b
            return L
```





```python
'''
	只有在 没有 找到属性的情况下，才调用__getattr__，已有的属性，比如name，不会在__getattr__中查找
'''

class Student(object):

    def __init__(self):
        self.name = 'Michael'

    def __getattr__(self, attr):
        if attr=='score':
            return 99
        
        # 返回函数也是完全可以的：
        if attr=='age':
            return lambda: 25
        
        # 注意到任意调用如s.abc都会返回None;若只响应特定的几个属性就需要针对除此之外的都抛出错误
         raise AttributeError('\'Student\' object has no attribute \'%s\'' % attr)
            
            
class Chain(object):

    def __init__(self, path=''):
        self._path = path

    def __getattr__(self, path):
        return Chain('%s/%s' % (self._path, path))

    def __str__(self):
        return self._path

    __repr__ = __str__
    
结果：
>>> Chain().status.user.timeline.list
'/status/user/timeline/list'
```





```python
__call__ 模糊了对象与函数的界限
	通过callable()函数，我们就可以判断一个对象是否是“可调用”对象。
```







## 枚举类

```python
from enum import Enum
Month = Enum('Month', ('Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'))
for name, member in Month.__members__.items():
    print(name, '=>', member, ',', member.value)
    
    
    
from enum import Enum, unique
# @unique装饰器可以帮助我们检查保证没有重复值
@unique
class Weekday(Enum):
    Sun = 0 # Sun的value被设定为0
    Mon = 1
    Tue = 2
    Wed = 3
    Thu = 4
    Fri = 5
    Sat = 6
    
 Weekday.Mon
	==Weekday(1)
 Weekday["Mon"]
 Weekday.Mon.value
```







## 元类

```python
'''
type()函数也允许我们动态创建出类来，也就是说，动态语言本身支持运行期动态创建类'''
'''
使用type()动态创建类以外，要控制类的创建行为，还可以使用metaclass。
'''
通过type()函数创建的类和直接写class是完全一样的，因为Python解释器遇到class定义时，仅仅是扫描一下class定义的语法，然后调用type()函数创建出class。

class Hello(object):
    def hello(self, name='world'):
        print('Hello, %s.' % name)
# 等价于下方
def fn(self, name='world'): # 先定义函数
	print('Hello, %s.' % name)
    
Hello = type('Hello', (object,), dict(hello=fn)) # 创建Hello class
```





`__init__`与`__new__`

```python
# https://www.cnblogs.com/shenxiaolin/p/9307496.html

__new__是在实例创建之前被调用的，因为它的任务就是创建实例然后返回该实例对象，是个静态方法。
__init__是当实例对象创建完成后被调用的，然后设置对象属性的一些初始值，通常用在初始化一个类实例的时候。是一个实例方法。
也就是： __new__先被调用，__init__后被调用，__new__的返回值（实例）将传递给__init__方法的第一个参数，然后__init__给这个实例设置一些参数。
```







### ORM模型

```python
class Field(object):

    def __init__(self, name, column_type):
        self.name = name
        self.column_type = column_type

    def __str__(self):
        return '<%s:%s>' % (self.__class__.__name__, self.name)
    
class StringField(Field):

    def __init__(self, name):
        super(StringField, self).__init__(name, 'varchar(100)')

class IntegerField(Field):

    def __init__(self, name):
        super(IntegerField, self).__init__(name, 'bigint')
        
        
class ModelMetaclass(type):

    def __new__(cls, name, bases, attrs):
        if name=='Model':
            return type.__new__(cls, name, bases, attrs)
        print('Found model: %s' % name)
        mappings = dict()
        for k, v in attrs.items():
            if isinstance(v, Field):
                print('Found mapping: %s ==> %s' % (k, v))
                mappings[k] = v
        for k in mappings.keys():
            attrs.pop(k)
        attrs['__mappings__'] = mappings # 保存属性和列的映射关系
        attrs['__table__'] = name # 假设表名和类名一致
        return type.__new__(cls, name, bases, attrs)
    
    
class Model(dict, metaclass=ModelMetaclass):

    def __init__(self, **kw):
        super(Model, self).__init__(**kw)

    def __getattr__(self, key):
        try:
            return self[key]
        except KeyError:
            raise AttributeError(r"'Model' object has no attribute '%s'" % key)

    def __setattr__(self, key, value):
        self[key] = value

    def save(self):
        fields = []
        params = []
        args = []
        for k, v in self.__mappings__.items():
            fields.append(v.name)
            params.append('?')
            args.append(getattr(self, k, None))
        sql = 'insert into %s (%s) values (%s)' % (self.__table__, ','.join(fields), ','.join(params))
        print('SQL: %s' % sql)
        print('ARGS: %s' % str(args))
        
        
class User(Model):
    # 定义类的属性到列的映射：
    id = IntegerField('id')
    name = StringField('username')
    email = StringField('email')
    password = StringField('password')

# 创建一个实例：
u = User(id=12345, name='Michael', email='test@orm.org', password='my-pwd')
# 保存到数据库：
u.save()


''' # 结果
Found model: User
Found mapping: email ==> <StringField:email>
Found mapping: password ==> <StringField:password>
Found mapping: id ==> <IntegerField:uid>
Found mapping: name ==> <StringField:username>
SQL: insert into User (password,email,username,id) values (?,?,?,?)
ARGS: ['my-pwd', 'test@orm.org', 'Michael', 12345]
'''
```









# 错误、调试与测试

```python
'异常' 是完全无法在程序运行过程中预测的
	比如写入文件的时候，磁盘满了，写不进去了，或者从网络抓取数据，网络突然断掉了。
'BaseException'    


try:
except:
except:
...
else:
	# 如果没有错误发生，可以在except语句块后面加一个else，当没有错误发生时，会自动执行else语句：    	
finally:

    
'调试'
	print
    assert	启动Python解释器时可以用-O参数来关闭assert
    import logging
    pdb
    	1.python -m pdb err.py
        2.import pdb; pdb.set_trace() # 运行到这里会自动暂停
	

```





## 测试

```python
    
'单元测试：目标驱动'
	单元测试通过后有什么意义呢？如果我们对abs()函数代码做了修改，只需要再跑一遍单元测试，如果通过，说明我们的修改不会对abs()函数原有的行为造成影响，如果测试不通过，说明我们的修改与原有行为不一致，要么修改代码，要么修改测试。
    # 确保一个程序模块的行为符合我们设计的测试用例

import unittest
'''
	以test开头的方法就是测试方法，不以test开头的方法不被认为是测试方法，测试的时候不会被执行。
	setUp与tearDown, 这两个方法会分别在每调用一个测试方法的前后分别被执行。
	设想你的测试需要启动一个数据库，这时，就可以在setUp()方法中连接数据库，在tearDown()方法中关闭数据库
'''
```



```python
import unittest

from mydict import Dict

class TestDict(unittest.TestCase):
    def setUp(self):
        print('setUp...')

    def tearDown(self):
        print('tearDown...')
        
    def test_init(self):
        d = Dict(a=1, b='test')
        self.assertEqual(d.a, 1)
        self.assertEqual(d.b, 'test')
        self.assertTrue(isinstance(d, dict))

    def test_key(self):
        d = Dict()
        d['key'] = 'value'
        self.assertEqual(d.key, 'value')

    def test_attr(self):
        d = Dict()
        d.key = 'value'
        self.assertTrue('key' in d)
        self.assertEqual(d['key'], 'value')

    def test_keyerror(self):
        d = Dict()
        with self.assertRaises(KeyError):
            value = d['empty']

    def test_attrerror(self):
        d = Dict()
        with self.assertRaises(AttributeError):
            value = d.empty
            
            
if __name__ == '__main__':
    unittest.main()	# 运行单元测试
```









# IO编程

## 文件读写

```python
# 1.由于文件读写时都有可能产生IOError，一旦出错，后面的f.close()就不会调用
try:
    f = open('/path/to/file', 'r')
    print(f.read())
finally:
    if f:
        f.close()
      
# 等价于
with open('/path/to/file', 'r') as f:
    print(f.read())

# 2.
'要根据需要决定怎么调用'
'如果文件很小，read()一次性读取最方便；'
'如果不能确定文件大小，反复调用read(size)比较保险；'
'如果是配置文件，调用readlines()最方便：'
	调用read()会一次性读取文件的全部内容，如果文件有10G，内存就爆了，所以，要保险起见，可以反复调用read(size)方法，每次最多读取size个字节的内容
	调用readline()可以每次读取一行内容
	调用readlines()一次读取所有内容并'按行返回'list

for line in f.readlines():
    print(line.strip()) # 把末尾的'\n'删掉
    
    
# 3.    
>>> f = open('/Users/michael/gbk.txt', 'r', encoding='gbk')
>>> f.read()
'测试'
遇到有些编码不规范的文件，你可能会遇到UnicodeDecodeError，因为在文本文件中可能夹杂了一些非法编码的字符。遇到这种情况，open()函数还接收一个errors参数，表示如果遇到编码错误后如何处理。最简单的方式是直接忽略：

>>> f = open('/Users/michael/gbk.txt', 'r', encoding='gbk', errors='ignore')


# 4.StringIO和BytesIO
# 数据读写不一定是文件，也可以在内存中读写
# StringIO操作的只能是str，如果要操作二进制数据，就需要使用BytesIO
from io import StringIO,BytesIO
>>> from io import StringIO
>>> f = StringIO()
>>> f.write('hello')
5
>>> f.write(' ')
1
>>> f.write('world!')
6
>>> print(f.getvalue())
hello world!

```





## 序列化

```python
import pickle

pickle.dumps(o) # 对象 -> 二进制字符串
pickle.dump(o,f) # 对象 -> 序列化后存储在文件f中
pickle.loads(s) # 二进制文本 -> 对象
pickle.load(f) # 将文件f中的字符 序列化成对象

# https://docs.python.org/3/library/json.html#json.dumps
import json
json.dumps
json.dump(d,f)

json.loads
json.load(f)


# 序列化其他对象
import json

class Student(object):
    def __init__(self, name, age, score):
        self.name = name
        self.age = age
        self.score = score
s = Student('Bob', 20, 88)


def student2dict(std):
    return {
        'name': std.name,
        'age': std.age,
        'score': std.score
    }
# 序列化
json.dumps(s, default=student2dict)
# json.dumps(s, default=lambda obj: obj.__dict__)

# 反序列化
json_str = '{"age": 20, "score": 88, "name": "Bob"}'
json.loads(json_str, object_hook=dict2student)
```







# 进程和线程

https://zhuanlan.zhihu.com/p/64702600

https://www.liujiangblog.com/course/python/79





## 多线程

```python
current_thread()	返回当前线程
active_count()	返回当前活跃的线程数，1个主线程+n个子线程
get_ident()	返回当前线程
enumerate()	返回当前活动 Thread 对象列表
main_thread()	返回主 Thread 对象

# ========================
'''
threading.Thread(self, group=None, target=None, name=None,
     args=(), kwargs=None, *, daemon=None)
     
两种使用线程的方式
	继承threading.Thread
	threading.Thread(target=...)
	
通过with语句使用线程锁
'''
threading模块包含下面的类：
    Thread：基本线程类
    Lock：互斥锁
    RLock：可重入锁，使单一进程再次获得已持有的锁(递归锁)
    Condition：条件锁，使得一个线程等待另一个线程满足特定条件，比如改变状态或某个值。
    Semaphore：信号锁。为线程间共享的有限资源提供一个”计数器”，如果没有可用资源则会被阻塞。
    	# 允许一定数量的线程同时更改数据
        
    Event：事件锁，任意数量的线程等待某个事件的发生，在该事件发生后所有线程被激活
    Timer：一种计时器
    Barrier：Python3.2新增的“阻碍”类，必须达到指定数量的线程后才可以继续执行。
    
start()	启动线程，等待CPU调度
run()	线程被cpu调度后自动执行的方法    
join([timeout])	调用该方法将会使主调线程堵塞，直到被调用线程运行结束或超时。参数timeout是一个数值类型，表示超时时间，如果未提供该参数，那么主调线程将一直堵塞到被调线程结束。

isDaemon()方法和daemon属性	是否为守护线程
getName()、setName()和name	用于获取和设置线程的名称。
setDaemon()	设置为后台线程或前台线程（默认是False，前台线程）。如果是后台线程，主线程执行过程中，后台线程也在进行，主线程执行完毕后，后台线程不论成功与否，均停止。如果是前台线程，主线程执行过程中，前台线程也在进行，主线程执行完毕后，等待前台线程执行完成后，程序才停止。
```





### join理解

```python
'''
一般情况下，主线程没有等待子线程t执行完毕，而是啥都不管，继续往下执行它自己的代码，执行完毕后也没有结束整个程序，而是等待子线程t执行完毕，整个程序才结束。

有时候我们希望主线程等等子线程，不要“埋头往前跑”。那要怎么办？使用join()方法！
'''

import time
import threading

def doWaiting():
    print('start waiting:', time.strftime('%H:%M:%S'))
    time.sleep(3)
    print('stop waiting', time.strftime('%H:%M:%S'))

t = threading.Thread(target=doWaiting)
t.start()
# 确保线程t已经启动
time.sleep(1)
print('start join')
# 将一直堵塞，直到t运行结束。
t.join()
print('end join')
```





#### 误区使用



```python
# 下段代码中使用join()方法，让多线程变成顺序执行
for i in range(2):     
    t = threading.Thread(target=plus)
    t.start()
    # 只用t线程执行完毕后，主线程才会继续执行for循环、让下一个子线程开始进入调度
    t.join()        # 添加这一行就让两个子线程变成了顺序执行
```





### Event锁

```python
'''
事件线程锁的运行机制：
	全局定义了一个Flag，如果Flag的值为False，那么当程序执行wait()方法时就会阻塞;
	如果Flag值为True，线程不再阻塞
	
clear(): 将事件的Flag设置为False。
set()：将Flag设置为True。
wait()：将等待“红绿灯”信号。
is_set():判断当前是否"绿灯放行"状态
'''
#利用Event类模拟红绿灯
import threading
import time

event = threading.Event()

def lighter():
    green_time = 5       # 绿灯时间
    red_time = 5         # 红灯时间
    event.set()          # 初始设为绿灯
    while True:
        print("\33[32;0m 绿灯亮...\033[0m")
        time.sleep(green_time)
        event.clear()
        print("\33[31;0m 红灯亮...\033[0m")
        time.sleep(red_time)
        event.set()

def run(name):
    while True:
        if event.is_set():      # 判断当前是否"放行"状态
            print("一辆[%s] 呼啸开过..." % name)
            time.sleep(1)
        else:
            print("一辆[%s]开来，看到红灯，无奈的停下了..." % name)
            event.wait()
            print("[%s] 看到绿灯亮了，瞬间飞起....." % name)

if __name__ == '__main__':

    light = threading.Thread(target=lighter,)
    light.start()

    for name in ['奔驰', '宝马', '奥迪']:
        car = threading.Thread(target=run, args=(name,))
        car.start()
```







### Condition锁

```python
'''
wait([timeout])方法将使线程进入Condition的等待池等待通知，并释放锁
	# 将被阻塞
notify()方法将从等待池挑选一个线程并通知，收到通知的线程将自动调用acquire()尝试获得锁定（进入锁定池），其他线程仍然在等待池中
notifyAll()方法将通知等待池中所有的线程，这些线程都将进入锁定池尝试获得锁定

'''

import threading
import time

num = 0
con = threading.Condition()

class Foo(threading.Thread):

    def __init__(self, name, action):
        super(Foo, self).__init__()
        self.name = name
        self.action = action

    def run(self):
        global num
        con.acquire()
        print("%s开始执行..." % self.name)
        while True:
            if self.action == "add":
                num += 1
            elif self.action == 'reduce':
                num -= 1
            else:
                exit(1)
            print("num当前为：", num)
            time.sleep(1)
            if num == 5 or num == 0:
                print("暂停执行%s！" % self.name)
                con.notify()
                con.wait()
                print("%s开始执行..." % self.name)
        con.release()

if __name__ == '__main__':
    a = Foo("线程A", 'add')
    b = Foo("线程B", 'reduce')
    a.start()
    b.start()
```







### Timer

```python
# 用于指定n秒后执行某操作。一个简单但很实用的东西。

from threading import Timer

def hello():
    print("hello, world")

# 表示1秒后执行hello函数
t = Timer(1, hello)
t.start()
```









### 生产者与消费者模式

```python
#!/usr/bin/env python
# -*- coding:utf-8 -*-
import time
import queue
import threading

q = queue.Queue(10)     # 生成一个队列，用来保存“包子”，最大数量为10

def productor(i):
    # 厨师不停地每2秒做一个包子
    while True:
        q.put("厨师 %s 做的包子！" % i)
        time.sleep(2)

def consumer(j):
    # 顾客不停地每秒吃一个包子
    while True:
        print("顾客 %s 吃了一个 %s"%(j,q.get()))
        time.sleep(1)

# 实例化了3个生产者（厨师）
for i in range(3):
    t = threading.Thread(target=productor, args=(i,))
    t.start()
# 实例化了10个消费者（顾客）
for j in range(10):
    v = threading.Thread(target=consumer, args=(j,))
    v.start()
```





### 线程池

```python
class ThreadPool:

    def __init__(self, max_num, max_task_num=None):
        """
        初始化线程池
        :param max_num: 线程池最大线程数量
        :param max_task_num: 任务队列长度
        """
        # 如果提供了最大任务数的参数，则将队列的最大元素个数设置为这个值。
        if max_task_num:
            self.q = queue.Queue(max_task_num)
        # 默认队列可接受无限多个的任务
        else:
            self.q = queue.Queue()
        # 设置线程池最多可实例化的线程数
        self.max_num = max_num
        # 任务取消标识
        self.cancel = False
        # 任务中断标识
        self.terminal = False
        # 已实例化的线程列表
        self.generate_list = []
        # 处于空闲状态的线程列表
        self.free_list = []

    def put(self, func, args, callback=None):
        """
        往任务队列里放入一个任务
        :param func: 任务函数
        :param args: 任务函数所需参数
        :param callback: 任务执行失败或成功后执行的回调函数，回调函数有两个参数
        1、任务函数执行状态；2、任务函数返回值（默认为None，即：不执行回调函数）
        :return: 如果线程池已经终止，则返回True否则None
        """
        # 先判断标识，看看任务是否取消了
        if self.cancel:
            return
        # 如果没有空闲的线程，并且已创建的线程的数量小于预定义的最大线程数，则创建新线程。
        if len(self.free_list) == 0 and len(self.generate_list) < self.max_num:
            self.generate_thread()
        # 构造任务参数元组，分别是调用的函数，该函数的参数，回调函数。
        w = (func, args, callback,)
        # 将任务放入队列
        self.q.put(w)

    def generate_thread(self):
        """
        创建一个线程
        """
        # 每个线程都执行call方法
        t = threading.Thread(target=self.call)
        t.start()

    def call(self):
        """
        循环去获取任务函数并执行任务函数。在正常情况下，每个线程都保存生存状态，  直到获取线程终止的flag。
        """
        # 获取当前线程的名字
        current_thread = threading.currentThread().getName()
        # 将当前线程的名字加入已实例化的线程列表中
        self.generate_list.append(current_thread)
        # 从任务队列中获取一个任务
        event = self.q.get()
        # 让获取的任务不是终止线程的标识对象时
        while event != StopEvent:
            # 解析任务中封装的三个参数
            func, arguments, callback = event
            # 抓取异常，防止线程因为异常退出
            try:
                # 正常执行任务函数
                result = func(current_thread, *arguments)
                success = True
            except Exception as e:
                # 当任务执行过程中弹出异常
                result = None
                success = False
            # 如果有指定的回调函数
            if callback is not None:
                # 执行回调函数，并抓取异常
                try:
                    callback(success, result)
                except Exception as e:
                    pass
            # 当某个线程正常执行完一个任务时，先执行worker_state方法
            with self.worker_state(self.free_list, current_thread):
                # 如果强制关闭线程的flag开启，则传入一个StopEvent元素
                if self.terminal:
                    event = StopEvent
                # 否则获取一个正常的任务，并回调worker_state方法的yield语句
                else:
                    # 从这里开始又是一个正常的任务循环
                    event = self.q.get()
        else:
            # 一旦发现任务是个终止线程的标识元素，将线程从已创建线程列表中删除
            self.generate_list.remove(current_thread)


    def close(self):
        """
        执行完所有的任务后，让所有线程都停止的方法
        """
        # 设置flag
        self.cancel = True
        # 计算已创建线程列表中线程的个数，
        # 然后往任务队列里推送相同数量的终止线程的标识元素
        full_size = len(self.generate_list)
        while full_size:
            self.q.put(StopEvent)
            full_size -= 1


    def terminate(self):
        """
        在任务执行过程中，终止线程，提前退出。
        """
        self.terminal = True
        # 强制性的停止线程
        while self.generate_list:
            self.q.put(StopEvent)

# 该装饰器用于上下文管理
    @contextlib.contextmanager
    def worker_state(self, state_list, worker_thread):
        """
        用于记录空闲的线程，或从空闲列表中取出线程处理任务
        """
        # 将当前线程，添加到空闲线程列表中
        state_list.append(worker_thread)
        # 捕获异常
        try:
            # 在此等待
            yield
        finally:
            # 将线程从空闲列表中移除
            state_list.remove(worker_thread)
```











## 多进程

### 补充

```python
# https://www.liujiangblog.com/course/python/82


'''
想要在windows中运行，必须使用if __name__ == '__main__':的方式，显然这只能用于调试和学习，不能用于实际环境
    os.getppid()  # 获取父进程id
    os.getpid()  # 获取自己的进程id
    
Process类的用法和Thread类几乎一模一样
    
进程间的数据共享
	在Linux中，每个子进程的数据都是由父进程提供的，每启动一个子进程就从父进程克隆一份数据。
		全局列表lis没有起到任何作用，在主进程和子进程中，lis指向内存中不同的列表。
'''

import os
import multiprocessing

def foo(i):
    # 同样的参数传递方法
    print("这里是 ", multiprocessing.current_process().name)
    print('模块名称:', __name__)
    print('父进程 id:', os.getppid())  # 获取父进程id
    print('当前子进程 id:', os.getpid())  # 获取自己的进程id
    print('------------------------')

if __name__ == '__main__':

    for i in range(5):
        p = multiprocessing.Process(target=foo, args=(i,))
        p.start()

```



#### 进程间的数据共享

##### Array

```python
'''
对于数据类型有下面的对应关系：
    'c': ctypes.c_char, 'u': ctypes.c_wchar,
    'b': ctypes.c_byte, 'B': ctypes.c_ubyte,
    'h': ctypes.c_short, 'H': ctypes.c_ushort,
    'i': ctypes.c_int, 'I': ctypes.c_uint,
    'l': ctypes.c_long, 'L': ctypes.c_ulong,
    'f': ctypes.c_float, 'd': ctypes.c_double
'''

from multiprocessing import Process,Array

def func(i,temp):
    temp[0] += 100
    print("进程%s " % i, ' 修改数组第一个元素后----->', temp[0])

if __name__ == '__main__':
    temp = Array('i', [1, 2, 3, 4])
    for i in range(10):
        p = Process(target=func, args=(i, temp))
        p.start()
        
        
'''
打印结果：
    进程2   修改数组第一个元素后-----> 101
    进程4   修改数组第一个元素后-----> 201
    进程5   修改数组第一个元素后-----> 301
    进程3   修改数组第一个元素后-----> 401
    进程1   修改数组第一个元素后-----> 501
    进程6   修改数组第一个元素后-----> 601
    进程9   修改数组第一个元素后-----> 701
    进程8   修改数组第一个元素后-----> 801
    进程0   修改数组第一个元素后-----> 901
    进程7   修改数组第一个元素后-----> 1001
'''
```





##### Manager

```python



from multiprocessing import Process, Manager

def func(i, dic):
    dic["num"] = 100+i
    print(dic.items())

if __name__ == '__main__':
    # 还支持其他格式，如：list/Array/Queue/
    dic = Manager().dict()
    for i in range(10):
        p = Process(target=func, args=(i, dic))
        p.start()
        p.join()
```





##### Pipe

```python
from multiprocessing import Process, Pipe
def fun1(conn):
    print('子进程发送消息：')
    conn.send('你好主进程')
    print('子进程接受消息：')
    print(conn.recv())
    conn.close()

if __name__ == '__main__':
    conn1, conn2 = Pipe() #关键点，pipe实例化生成一个双向管
    p = Process(target=fun1, args=(conn2,)) #conn2传给子进程
    p.start()
    print('主进程接受消息：')
    print(conn1.recv())
    print('主进程发送消息：')
    conn1.send("你好子进程")
    p.join()
    print('结束测试')
'''
结果

    主进程接受消息：
    子进程发送消息：
    子进程接受消息：
    你好主进程
    主进程发送消息：
    你好子进程
    结束测试
'''
```







##### queues

```python
'''
关于queue和Queue，在Python库中非常频繁的出现，很容易就搞混淆了。

甚至是multiprocessing自己还有一个Queue类(大写的Q)，一样能实现queues.Queue的功能，导入方式是from multiprocessing import Queue

'''
import multiprocessing
from multiprocessing import Process,queues

def func(i, q):
    ret = q.get()
    print("进程%s从队列里获取了一个%s，然后又向队列里放入了一个%s" % (i, ret, i))
    q.put(i)

if __name__ == "__main__":
    # 注意这里的用法
    lis = queues.Queue(20, ctx=multiprocessing)
    lis.put(0)
    for i in range(10):
        p = Process(target=func, args=(i, lis,))
        p.start()
'''
运行结果：
    进程1从队列里获取了一个0，然后又向队列里放入了一个1
    进程4从队列里获取了一个1，然后又向队列里放入了一个4
    进程2从队列里获取了一个4，然后又向队列里放入了一个2
    进程6从队列里获取了一个2，然后又向队列里放入了一个6
    进程0从队列里获取了一个6，然后又向队列里放入了一个0
    进程5从队列里获取了一个0，然后又向队列里放入了一个5
    进程9从队列里获取了一个5，然后又向队列里放入了一个9
    进程7从队列里获取了一个9，然后又向队列里放入了一个7
    进程3从队列里获取了一个7，然后又向队列里放入了一个3
    进程8从队列里获取了一个3，然后又向队列里放入了一个8
'''
```











#### 进程锁

```python
from multiprocessing import Process
from multiprocessing import Array
from multiprocessing import RLock, Lock, Event, Condition, Semaphore
import time

def func(i,lis,lc):
    lc.acquire()
    lis[0] = lis[0] - 1
    time.sleep(1)
    print('say hi', lis[0])
    lc.release()

if __name__ == "__main__":
    array = Array('i', 1)
    array[0] = 10
    lock = RLock()
    for i in range(10):
        p = Process(target=func, args=(i, array, lock))
        p.start()
'''
运行结果：

    say hi 9
    say hi 8
    say hi 7
    say hi 6
    say hi 5
    say hi 4
    say hi 3
    say hi 2
    say hi 1
    say hi 0
'''
```







### 获取返回值 ！

```python
def func():
    return 2**3**4

p = multiprocessing.Pool()
result = p.apply_async(func).get()
print(result)

# ============方法二===========
class Result():
    def __init__(self):
        self.val = None

    def update_result(self, val):
        self.val = val

result = Result()

def f(x):
    return x*x

pool.apply_async(f, (10,), callback=result.update_result)
```







### 进程池

```python
'''
进程池：其他方法

    apply() 同步执行（串行）
    apply_async() 异步执行（并行）
    terminate() 立刻关闭进程池
    join() 主进程等待所有子进程执行完毕。必须在close或terminate()之后。
    close() 等待所有进程结束后，才关闭进程池。
'''


from multiprocessing import Pool
import os, time, random

def long_time_task(name):
    print('Run task %s (%s)...' % (name, os.getpid()))
    start = time.time()
    time.sleep(random.random() * 3)
    end = time.time()
    print('Task %s runs %0.2f seconds.' % (name, (end - start)))

if __name__=='__main__':
    print('Parent process %s.' % os.getpid())
    p = Pool(4)
    for i in range(5):
        p.apply_async(long_time_task, args=(i,))
    print('Waiting for all subprocesses done...')
    
    # 对Pool对象调用join()方法会等待所有子进程执行完毕，调用join()之前必须先调用close()，调用close()之后就不能继续添加新的Process了。
    p.close()
    p.join()
    print('All subprocesses done.')
```









### subprocess

https://www.cnblogs.com/songhaixing/p/14275042.html

https://www.runoob.com/w3cnote/python3-subprocess.html



```python

subprocess.run(
    args, # 要执行的命令。必须是一个字符串 或 字符串参数列表
    *, 
    input=None, 
    stdin=None, 
    stdout=None,
    stderr=None, 
    shell=False,  # 在windows中，args和shell参数组合比较复杂，根据命令的不同有不同的情况。建议shell设置为True
    timeout=None, # 命令执行时间超时，子进程将被杀死，并弹出TimeoutExpired异常
    check=False,  # 如果该参数设置为True，并且进程退出状态码不是0，则弹出CalledProcessError异常
    encoding=None, # 如果指定了该参数，则stdin、stdout和stderr可以接收字符串数据，并以该编码方式编码。否则只接收bytes类型的数据
    errors=None
)

# 返回值：CompletedProcess 类型
args 启动进程的参数，通常是个列表或字符串。

stdout 获取子进程的stdout。通常为bytes类型序列，None表示没有捕获值。如果你在调用run()方法时，设置了参数stderr=subprocess.STDOUT，则错误信息会和stdout一起输出，此时stderr的值是None。

stderr 获取子进程的错误信息。通常为bytes类型序列，None表示没有捕获值。

returncode 进程结束状态返回码。0表示成功状态。
check_returncode() 用于检查返回码。如果返回状态码不为零，弹出CalledProcessError异常。


# =============================================
'''要获取命令执行的结果或者信息，在调用run()方法的时候，请指定stdout=subprocess.PIPE'''
ret=subprocess.run("dir",shell=True,stdout=subprocess.PIPE)
print(ret.stdout.decode("gbk"))
```







#### 接收参数 | !

```python

import subprocess

fd = open("d:\\1.txt")
ret = subprocess.run("python", stdin=fd, stdout=subprocess.PIPE,shell=True)
print(ret.stdout)
fd.close()

# ============================================
# 返回值是一个Popen对象，而不是CompletedProcess对象
import subprocess

s = subprocess.Popen("python", stdout=subprocess.PIPE, stdin=subprocess.PIPE, shell=True)
s.stdin.write(b"import os\n")
s.stdin.write(b"print(os.environ)")
s.stdin.close()

out = s.stdout.read().decode("GBK")
s.stdout.close()
print(out)

'''
channel=Popen()
	channel.poll()	返回0表示正常返回
	channel.wait(timeout): 等待子进程终止。 
	error,output=channel.communicate(input,timeout)	和子进程交互，发送和读取数据。 
	
	channel.kill()
	channel.terminate()
	channel.send_signal(SIGNAL)
	
	
# 案列一
import time
import subprocess
def cmd(command):
    subp = subprocess.Popen(command,shell=True,stdout=subprocess.PIPE,stderr=subprocess.PIPE,encoding="utf-8")
    subp.wait(2)
    if subp.poll() == 0:
        print(subp.communicate()[1])
    else:
        print("失败")
cmd("java -version")
cmd("exit 1")



# 案列二
import subprocess

res1 = subprocess.Popen(     # 开启的第一的进程
    "dir",               
    shell=True,
    stdout=subprocess.PIPE,
    stderr=subprocess.PIPE,
)

res2 = subprocess.Popen(     # 开启的第二个进程
    "findstr html*",    # 等价于"dir | findstr html*",  # 使用管道符号运行命令  
    shell=True,
    stdin=res1.stdout,       # 将第一个进程的正确输出结果拿到做处理
    stdout=subprocess.PIPE,
    stderr=subprocess.PIPE,
)

result = res2.stdout.read()
result= str(result,encoding="gbk")
print(result)
'''


# ============================================
import subprocess

print('$ nslookup')
p = subprocess.Popen(['nslookup'], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
# p.communicate()

output, err = p.communicate(b'set q=mx\npython.org\nexit\n')
print(output.decode('utf-8'))
print('Exit code:', p.returncode)


```











## 多线程

```python
'''
多进程中，同一个变量，各自有一份拷贝存在于每个进程中，互不影响;
而多线程中，所有变量都由所有线程共享，所以，任何一个变量都可以被任何一个线程修改。
因此，线程之间共享数据最大的危险在于多个线程同时改一个变量，把内容给改乱了
'''
```



### 互斥锁原因

```python
'''
高级语言的一条语句在CPU执行时是若干条语句，即使一个简单的计算：

balance = balance + n
也分两步：
    x = balance + n		 # 由于x是局部变量，两个线程各自都有自己的x
    balance = x
    
    
锁的好处就是确保了某段关键代码只能由一个线程从头到尾完整地执行，坏处当然也很多，首先是阻止了多线程并发执行，包含锁的某段代码实际上只能以单线程模式执行，效率就大大地下降了。

其次，由于可以存在多个锁，不同的线程持有不同的锁，并试图获取对方持有的锁时，可能会造成死锁，导致多个线程全部挂起，既不能执行，也无法结束，只能靠操作系统强制终止。

GIL锁(Global Interpreter Lock):多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核。
'''


import time, threading

# 假定这是你的银行存款:
balance = 0

def change_it(n):
    # 先存后取，结果应该为0:
    global balance
    balance = balance + n
    balance = balance - n

def run_thread(n):
    for i in range(2000000):
        change_it(n)

t1 = threading.Thread(target=run_thread, args=(5,))
t2 = threading.Thread(target=run_thread, args=(8,))
t1.start()
t2.start()
t1.join()
t2.join()
print(balance)
```









## ThreadLocal | ！

```javascript
let a=1
function A(){
    let a="Hello,World"
    B()
}
function B(){
    console.log("a=",a)
}
A() // a= 1
```

```python
a=1
def A():
	a="Hello World"
	B()
	
def B():
	print("a=",a)
	
A() # 打印结果也是：a=1
```











```python
'''
因为全局变量 会影响代码结构的原子性 导致结果出错
所以 能尽量使用各线程自己的 局部变量，就尽量使用局部变量
	局部变量只有线程自己能看见，不会影响其他线程，而全局变量的修改必须加锁
	
但是这会带来一个问题，线程中的局部变量 如何传递给其他函数(上面已经清晰的表明不能省略变量的传递)
'''

# ==============问题:1=============
def process_student(name):
    std = Student(name)
    # std是局部变量，但是每个函数都要用它，因此必须传进去：
    do_task_1(std)
    do_task_2(std)

def do_task_1(std):
    do_subtask_1(std)
    do_subtask_2(std)

def do_task_2(std):
    do_subtask_2(std)
    do_subtask_2(std)

    
# ===============解决：1==============
global_dict = {}

def std_thread(name):
    std = Student(name)
    # 把std放到全局变量global_dict中：
    global_dict[threading.current_thread()] = std
    do_task_1()
    do_task_2()

def do_task_1():
    # 不传入std，而是根据当前线程查找：
    std = global_dict[threading.current_thread()]
    # ...

def do_task_2():
    # 任何函数都可以查找出当前线程的std变量：
    std = global_dict[threading.current_thread()]
    
# ===============解决：2=================
threading_local=threading.local()

def std_thread(name):
    std=Student(name)
    threading_locale.student=std
    do_task_1()
    do_taks_2()
    
def do_task_1():
    std=threading_locale.student
    # ...
def do_task_2():
    std=threading_locale.student
     # ...

```



```python
'''
每个Thread对它都可以读写student属性，但互不影响。
	可以把local_school看成全局变量，但每个属性(如local_school.student)都是线程的局部变量，可以任意读写而互不干扰，也不用管理锁的问题，ThreadLocal内部会处理
	
一个ThreadLocal变量虽然是全局变量，但每个线程都只能读写自己线程的独立副本，互不干扰
'''
import threading
    
# 创建全局ThreadLocal对象:
local_school = threading.local()

def process_student():
    # 获取当前线程关联的student:
    std = local_school.student
    print('Hello, %s (in %s)' % (std, threading.current_thread().name))

def process_thread(name):
    # 绑定ThreadLocal的student:
    local_school.student = name
    process_student()

t1 = threading.Thread(target= process_thread, args=('Alice',), name='Thread-A')
t2 = threading.Thread(target= process_thread, args=('Bob',), name='Thread-B')
t1.start()
t2.start()
t1.join()
t2.join()
执行结果：

Hello, Alice (in Thread-A)
Hello, Bob (in Thread-B)
```









## 进程 VS 线程 | !

```markdown
# https://www.liaoxuefeng.com/wiki/1016959663602400/1017631469467456
`多进程模式最大的优点就是稳定性高`，因为一个子进程崩溃了，不会影响主进程和其他子进程。（当然主进程挂了所有进程就全挂了，但是Master进程只负责分配任务，挂掉的概率低）著名的Apache最早就是采用多进程模式。

多进程模式的缺点是创建进程的代价大，在Unix/Linux系统下，用fork调用还行，在Windows下创建进程开销巨大。另外，操作系统能同时运行的进程数也是有限的，在内存和CPU的限制下，如果有几千个进程同时运行，操作系统连调度都会成问题。

多线程模式通常比多进程快一点，但是也快不到哪去，而且，`多线程模式致命的缺点就是任何一个线程挂掉都可能直接造成整个进程崩溃，因为所有线程共享进程的内存`。



# 线程切换
无论是多进程还是多线程，只要数量一多，效率肯定上不去，为什么呢？
	如果有几千个任务同时进行，操作系统可能就主要忙着切换任务，根本没有多少时间去执行任务了，这种情况最常见的就是硬盘狂响，点窗口无反应，系统处于假死状态。
	所以，多任务一旦多到一个限度，就会消耗掉系统所有的资源，结果效率急剧下降，所有任务都做不好
	
	
# 计算密集型 vs. IO密集型
	计算密集型任务由于主要消耗CPU资源，因此，代码运行效率至关重要。Python这样的脚本语言运行效率很低，完全不适合计算密集型任务。对于计算密集型任务，最好用C语言编写。
	涉及到网络、磁盘IO的任务都是IO密集型任务(如：Web应用)，这类任务的特点是CPU消耗很少，任务的大部分时间都在等待IO操作完成（因为IO的速度远远低于CPU和内存的速度）；最合适的语言就是开发效率最高（代码量最少）的语言，脚本语言是首选，C语言最差
# 异步IO
	考虑到CPU和IO之间巨大的速度差异，一个任务在执行的过程中大部分时间都在等待IO操作，单进程单线程模型会导致别的任务无法并行执行
	现代操作系统对IO操作已经做了巨大的改进，最大的特点就是支持异步IO。
	如果充分利用操作系统提供的异步IO支持，就可以用单进程单线程模型来执行多任务，这种全新的模型称为事件驱动模型，Nginx就是支持异步IO的Web服务器
```









## 分布式进程

```python
'''
注意以下代码适用于Mac环境，window下可能并不适用

Process可以分布到多台机器上，而Thread最多只能分布到同一台机器的多个CPU上。
'''

```





```python
# 发起者：主体
# task_master.py

import random, time, queue
from multiprocessing.managers import BaseManager

# 发送任务的队列:
task_queue = queue.Queue()
# 接收结果的队列:
result_queue = queue.Queue()

# 从BaseManager继承的QueueManager:
class QueueManager(BaseManager):
    pass

# 把两个Queue都注册到网络上, callable参数关联了Queue对象:
QueueManager.register('get_task_queue', callable=lambda: task_queue)
QueueManager.register('get_result_queue', callable=lambda: result_queue)
# 绑定端口5000, 设置验证码'abc':
manager = QueueManager(address=('', 5000), authkey=b'abc')
# 启动Queue:
manager.start()
# 获得通过网络访问的Queue对象:
task = manager.get_task_queue()
result = manager.get_result_queue()
# 放几个任务进去:
for i in range(10):
    n = random.randint(0, 10000)
    print('Put task %d...' % n)
    task.put(n)
# 从result队列读取结果:
print('Try get results...')
for i in range(10):
    r = result.get(timeout=10)
    print('Result: %s' % r)
# 关闭:
manager.shutdown()
print('master exit.')
```





```python
# 在另一台机器上启动任务进程（本机上启动也可以）
# task_worker.py

import time, sys, queue
from multiprocessing.managers import BaseManager

# 创建类似的QueueManager:
class QueueManager(BaseManager):
    pass

# 由于这个QueueManager只从网络上获取Queue，所以注册时只提供名字:
QueueManager.register('get_task_queue')
QueueManager.register('get_result_queue')

# 连接到服务器，也就是运行task_master.py的机器:
server_addr = '127.0.0.1'
print('Connect to server %s...' % server_addr)
# 端口和验证码注意保持与task_master.py设置的完全一致:
m = QueueManager(address=(server_addr, 5000), authkey=b'abc')
# 从网络连接:
m.connect()
# 获取Queue的对象:
task = m.get_task_queue()
result = m.get_result_queue()
# 从task队列取任务,并把结果写入result队列:
for i in range(10):
    try:
        n = task.get(timeout=1)
        print('run task %d * %d...' % (n, n))
        r = '%d * %d = %d' % (n, n, n*n)
        time.sleep(1)
        result.put(r)
    except Queue.Empty:
        print('task queue is empty.')
# 处理结束:
print('worker exit.')
```







# 常用内建模块

### collections

#### namedtuple

```python
>> from collections import namedtuple
>>> Point = namedtuple('Point', ['x', 'y'])
>>> p = Point(1, 2)
>>> p.x
1
>>> p.y
2

>>> isinstance(p, Point)
True
>>> isinstance(p, tuple)
True
```





#### defaultdict

```python
# 使用dict时，如果引用的Key不存在，就会抛出KeyError。如果希望key不存在时，返回一个默认值，就可以用defaultdict
# 回调函数

>>> from collections import defaultdict
>>> dd = defaultdict(lambda: 'N/A')
>>> dd['key1'] = 'abc'
>>> dd['key1'] # key1存在
'abc'
>>> dd['key2'] # key2不存在，返回默认值
'N/A'
```





#### OrderedDict

```python
'''
现在dict 功能已经类似于 OrderdDict
'''
使用dict时，Key是无序的。在对dict做迭代时，我们无法确定Key的顺序。
# 如果要保持Key的顺序，可以用OrderedDict：
# orderedDict的Key会按照插入的顺序排列，不是Key本身排序：


from collections import OrderedDict

class LastUpdatedOrderedDict(OrderedDict):

    def __init__(self, capacity):
        super(LastUpdatedOrderedDict, self).__init__()
        self._capacity = capacity

    def __setitem__(self, key, value):
        containsKey = 1 if key in self else 0
        if len(self) - containsKey >= self._capacity:
            # 弹出最早添加的键值对；不加last=True就是弹出新添加的键值对了
            last = self.popitem(last=False)
            print('remove:', last)
        if containsKey:
            del self[key]
            print('set:', (key, value))
        else:
            print('add:', (key, value))
        OrderedDict.__setitem__(self, key, value)
```



#### ChainMap

```python
# hainMap本身也是一个dict，但是查找的时候，会按照顺序在内部的dict依次查找
# 可以用ChainMap实现参数的优先级查找，即先查命令行参数，如果没有传入，再查环境变量，如果没有，就使用默认参数
```



```python
from collections import ChainMap
import os, argparse

# 构造缺省参数:
defaults = {
    'color': 'red',
    'user': 'guest'
}

# 构造命令行参数:
parser = argparse.ArgumentParser()
parser.add_argument('-u', '--user')
parser.add_argument('-c', '--color')
namespace = parser.parse_args()
command_line_args = { k: v for k, v in vars(namespace).items() if v }

# 组合成ChainMap:
combined = ChainMap(command_line_args, os.environ, defaults)

# 打印参数:
print('color=%s' % combined['color'])
print('user=%s' % combined['user'])


'''
没有任何参数时，打印出默认参数：
$ python3 use_chainmap.py 
color=red
user=guest

当传入命令行参数时，优先使用命令行参数：
$ python3 use_chainmap.py -u bob
color=red
user=bob

同时传入命令行参数和环境变量，命令行参数的优先级较高：
$ user=admin color=green python3 use_chainmap.py -u bob
color=green
user=bob
'''
```









### queue | ！

```python
# https://www.liujiangblog.com/course/python/59
'''
微型轻量级的消息队列模块，queue
适合多线程时的消息交换。它实现了常见的锁语法，临时阻塞线程，防止竞争，这有赖于Python对线程的支持
	FIFO:先进先出队列，类似管道
	LIFO:后进先出队列，也就是栈
	priority queue：优先级队列，每个元素都带有一个优先值，值越小的越早出去。值相同的，先进入队列的先出去。
'''

'''
class 类型种类
	如果队列满了，则会暂时阻塞队列，直到有消费者取走元素
	queue.Queue(maxsize=0)
	queue.LifoQueue(maxsize=0)
	queue.PriorityQueue(maxsize=0)
	
exception:异常种类
	queue.Empty			# 从空的队列里请求元素的时候，弹出该异常
	 queue.Full			# 放入元素的时候，弹出该异常
'''
'''
	阻塞 可以简单的理解成 死循环，会停在被阻塞的代码处，直到阻塞结束在继续运行
'''

Queue.qsize()
	返回当前队列内的元素的个数。注意，qsize()大于零不等于下一个get()方法一定不会被阻塞，qsize()小于maxsize也不表示下一个put()方法一定不会被阻塞。

Queue.empty()
	队列为空则返回True，否则返回False。同样地，返回True不表示下一个put()方法一定不会被阻塞。返回False不表示下一个get()一定不会被阻塞。

Queue.full()
	与empty()方法正好相反。同样不保证下一步的操作不被阻塞。

Queue.put(item, block=True, timeout=None)
	item参数表示具体要放入队列的元素。block和timeout两个参数配合使用。其中，如果block=True，timeout=None，队列阻塞，直到有空槽出现；当block=True，timeout=正整数N，如果在等待了N秒后，队列还没有空槽，则弹出Full异常；如果block=False，则timeout参数被忽略，队列有空槽则立即放入，如果没空槽，则弹出Full异常。

Queue.put_nowait(item)
	等同于put(item, False)

Queue.get(block=True, timeout=None)
	从队列内删除并返回一个元素。如果block=True, timeout=None，队列会阻塞，直到有可供弹出的元素。如果timeout指定为一个正整数N，则在N秒内如果队列内没有可供弹出的元素，则抛出Empty异常。如果block=False，timeout参数会被忽略，此时队列内如果有元素则直接弹出，无元素可弹，则抛出Empty异常。

Queue.get_nowait()
	等同于get(False).

# 下面的两个方法用于跟踪排队的任务是否被消费者守护线程完全处理。

Queue.task_done()
	# 最好在每一次get之后，调用task_done()
	表明先前的队列任务已完成。由消费者线程使用。

Queue.join()
	阻塞队列，直到队列内的所有元素被获取和处理。
	当有元素进入队列时未完成任务的计数将增加	# 对比put与get调用的次数
    每当有消费者线程调用task_done()方法表示一个任务被完成时，未完成任务的计数将减少。
    当该计数变成0的时候，join()方法将不再阻塞。


```



#### PriorityQueue

```python
>>> q = queue.PriorityQueue()
>>> q.put((3,"haha"))
>>> q.put((2,"heihei"))
>>> q.put((1,"hehe"))
>>> q.get()
(1, 'hehe')
>>> q.get()
(2, 'heihei')
>>> q
```





#### 案列

```python
#!/usr/bin/env python
# -*- coding:utf-8 -*-
import time
import queue
import threading


def worker(i):
    while True:
        item = q.get()
        if item is None:
            print("线程%s发现了一个None,可以休息了^-^" % i)
            break
        # do_work(item)做具体的工作
        time.sleep(0.5)
        print("线程%s将任务<%s>完成了！" % (i, item))
        # 做完后发出任务完成信号，然后继续下一个任务
        q.task_done()


if __name__ == '__main__':
    num_of_threads = 5

    source = [i for i in range(1, 21)]  # 模拟20个任务

    # 创建一个FIFO队列对象，不设置上限
    q = queue.Queue()
    # 创建一个线程池
    threads = []
    # 创建指定个数的工作线程，并讲他们放到线程池threads中
    for i in range(1, num_of_threads+1):
        t = threading.Thread(target=worker, args=(i,))
        threads.append(t)
        t.start()

    # 将任务源里的任务逐个放入队列
    for item in source:
        time.sleep(0.5)     # 每隔0.5秒发布一个新任务
        q.put(item)

    # 阻塞队列直到队列里的任务都完成了
    q.join()
    print("-----工作都完成了-----")
    # 停止工作线程
    for i in range(num_of_threads):
        q.put(None)
    for t in threads:
        t.join()
    print(threads)
```









### bisect

```python
# 必须在已经排列好顺序的列表中使用
# 核心算法：二分法
from bisect

# 找索引
bisect.bisect_left(nums,x,lo,hi)
bisect.bisect_right(nums,x,lo,hi)
	# 区别在于当nums存在重复数值，例如:nums=[1,2,4,6,6,6,10,14]时，若x=6，应返回哪个索引值
	# 等价于 bisect.bisectt(nums,x,lo,hi)
    
# 插入
bisect.insort_left(nums,x,lo,hi)
bisect.insort_right(nums,x,lo,hi)
	# 等价于  bisect.insort(nums,x,lo,hi)


```











### itertools

```python
# 无限迭代器：repeat、count、cycle

# 1.count
>>> import itertools
>>> naturals = itertools.count(1)
>>> for n in natuals:
...     print(n)
...
1
2
3
...

# 2.cycle
# cycle()会把传入的一个序列无限重复下去：
>>> import itertools
>>> cs = itertools.cycle('ABC') # 注意字符串也是序列的一种
>>> for c in cs:
...     print(c)
...
'A'
'B'
'C'
'A'
'B'
'C'
...


# 3.repeat
# repeat()负责把一个元素无限重复下去，不过如果提供第二个参数就可以限定重复次数：
>>> ns = itertools.repeat('A', 3)
>>> for n in ns:
...     print(n)
...
A
A
A




# ===================
# 截取/组合：takewhile/chain、groupby
>>> natuals = itertools.count(1)
>>> ns = itertools.takewhile(lambda x: x <= 10, natuals)
>>> list(ns)
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]




# chain()可以把一组迭代对象串联起来，形成一个更大的迭代器：
>>> for c in itertools.chain('ABC', 'XYZ'):
...     print(c)
# 迭代效果：'A' 'B' 'C' 'X' 'Y' 'Z'



# groupby()把迭代器中相邻的重复元素挑出来放在一起：
>>> for key, group in itertools.groupby('AaaBBbcCAAa', lambda c: c.upper()):
...     print(key, list(group))
...
A ['A', 'a', 'a']
B ['B', 'B', 'b']
C ['c', 'C']
A ['A', 'A', 'a']

```







### contextlib | 上下文管理

```python
# https://www.cnblogs.com/nnnkkk/p/4309275.html


with语句不仅可以管理文件，还可以管理锁、连接等等
#管理锁
import  threading
lock = threading.lock()
with lock:
    #执行一些操作
    pass
```



#### `__enter__`和`__exit__`

```python
class Query(object):

    def __init__(self, name):
        self.name = name

    def __enter__(self):
        print('Begin')
        return self
    
    def __exit__(self, exc_type, exc_value, traceback):
        if exc_type:
            print('Error')
        else:
            print('End')
    
    def query(self):
        print('Query info about %s...' % self.name)
        
        
with Query('Bob') as q:
    q.query()
```





##### 实现局部作用域

```python
class Scope:
    def __init__(self):
        pass
    def __enter__(self):
       
    def __exit__(self):
        pass+
```









#### @contextmanager

```python
# 希望在某段代码执行前后自动执行特定代码
@contextmanager
def tag(name):
    print("<%s>" % name)
    yield
    print("</%s>" % name)

with tag("h1"):
    print("hello")
    print("world")
    
    
'''
上述代码执行结果为：
    <h1>
    hello
    world
    </h1>
'''


# =================================
# 锁资源自动获取和释放的例子

 1 @contextmanager
 2 def locked(lock):
 3     lock.acquire()
 4     try:
 5         yield
 6     finally:
 7         lock.release()
 8 
 9 with locked(myLock):
10     #代码执行到这里时，myLock已经自动上锁
11     pass
12     #执行完后会，会自动释放锁

```





#### closing

```python
如果一个'具有close方法的对象'没有实现上下文，我们就不能把它用于with语句。这个时候，可以用closing()来把该对象变为上下文对象

# ==========实现方式:1============
@contextmanager
def closing(thing):
    try:
        yield thing
    finally:
        thing.close()

# ==========实现方式:2============
1 class closing(object):
18     def __init__(self, thing):
19         self.thing = thing
20     def __enter__(self):
21         return self.thing
22     def __exit__(self, *exc_info):
23         self.thing.close()
        
        
# ==========实现方式============
with closing(urlopen('https://www.python.org')) as page:
    for line in page:
        print(line)
```





#### nested

```python
# 用来嵌套多个上下文管理器，等同于下面的形式:　　

with mgr1:
    with mgr2:
        ...
        with mgrn:
            pass

# ==========案列============
from contextlib import contextmanager
from contextlib import nested
from contextlib import closing

@contextmanager
def my_context(name):
    print("enter")
    try:
        yield name
    finally:
        print("exit")

#使用nested函数来调用多个管理器
print("---------使用nested函数调用多个管理器-----------")
with nested(my_context("管理器一"), my_context("管理器二"),my_context("管理器三")) as (m1,m2,m3):
    print(m1)
    print(m2)
    print(m3)

#直接使用with来调用调用多个管理器
print("---------使用with调用多个管理器-----------")
with my_context("管理器一") as m1, my_context("管理器二") as m2, my_context("管理器三") as m3:
    print(m1)
    print(m2)
    print(m3)
```











### urllib

```python
from urllib import request

req = request.Request('http://www.douban.com/')
req.add_header('User-Agent', 'Mozilla/6.0 (iPhone; CPU iPhone OS 8_0 like Mac OS X) AppleWebKit/536.26 (KHTML, like Gecko) Version/8.0 Mobile/10A5376e Safari/8536.25')
with request.urlopen(req) as f:
    print('Status:', f.status, f.reason)
    for k, v in f.getheaders():
        print('%s: %s' % (k, v))
    print('Data:', f.read().decode('utf-8'))



```







### hashlib、base64、hmac

```python
import base64
base64.b64encode(s1)
base64.b64decode(s2)


# 摘要算法
# 摘要算法之所以能指出数据是否被篡改过，就是因为摘要函数是一个单向函数，计算f(data)很容易，但通过digest反推data却非常困难。而且，对原始数据做一个bit的修改，都会导致计算出的摘要完全不同
# 加盐：为了防止黑客通过彩虹表根据哈希值反推原始口令，在计算哈希的时候，不能仅针对原始输入计算，需要增加一个salt来使得相同的输入也能得到不同的哈希，这样，大大增加了黑客破解的难度

如果数据量很大，可以分块多次调用update()，最后计算的结果是一样的：
# 生成结果是固定的128 bit字节，通常用一个32位的16进制字符串表示。
import hashlib

md5 = hashlib.md5()
md5.update('how to use md5 in '.encode('utf-8'))
md5.update('python hashlib?'.encode('utf-8'))
print(md5.hexdigest())



sha1 = hashlib.sha1()
sha1.update('how to use sha1 in '.encode('utf-8'))
sha1.update('python hashlib?'.encode('utf-8'))
print(sha1.hexdigest())
SHA1的结果是160 bit字节，通常用一个40位的16进制字符串表示。




# 把salt看做一个“口令”，加salt的哈希就是：计算一段message的哈希时，根据不同口令计算出不同的哈希。要验证哈希值，必须同时提供正确的口令
# Hmac算法：Keyed-Hashing for Message Authentication。通过一个标准算法，在计算哈希的过程中，把key混入计算过程中。
import  hmac

>>> import hmac
>>> message = b'Hello, world!'
>>> key = b'secret'
>>> h = hmac.new(key, message, digestmod='MD5')
>>> # 如果消息很长，可以多次调用h.update(msg)
>>> h.hexdigest()
'fa4ee7d173f2d97ee79022d1a7355bcf'
```





# 常用第三方模块

## virtualenv

```python
# 隔离环境，局部模块，不会污染全局模块
# python虚拟环境  ->  JS的node_modules环境
# Lib/site_packages

virtualenv  work_directory # 创建名为work_directory的虚拟环境
source ./work_directory/Scripts/activate # 必须激活，之后才可以安装其他包
./work_directory/Scripts/deactivate	# 退出当前虚拟环境

# 只有在source之后才可 安装其他包
pip install requests # 安装其他软件
pip freeze > requirements	# 将环境依赖包的信息保存到requirements.txt文件中，类似packages.json文件

'''
不会在每次卸载包或安装包，智能地修改requirements.txt中的内容;
因此 每次卸载包或安装包 必须将当前依赖重新写入 ，即 运行命令：pip freeze > requirements
'''
pip uninstall -y requests	# 卸载requests包，注意必须加-y
pip install -r requirements.txt # 安装 requirements.txt文件中的包 -> npm install

```





## chardet

```python
对于未知编码的bytes，要把它转换成str，需要先“猜测”编码。猜测的方式是先收集各种编码的特征字符，根据特征字符判断，就能有很大概率“猜对”。



当我们拿到一个bytes时，就可以对其检测编码。用chardet检测编码，只需要一行代码：
# confidence字段，表示检测的概率是1.0（即100%
>>> chardet.detect(b'Hello, world!')
{'encoding': 'ascii', 'confidence': 1.0, 'language': ''}


>>> data = '离离原上草，一岁一枯荣'.encode('gbk')
>>> chardet.detect(data)
{'encoding': 'GB2312', 'confidence': 0.7407407407407407, 'language': 'Chinese'}
```









# 异步IO

## 协程

```python
'''
协程的切换不同于线程切换，是由程序自身控制的，没有切换的开销
协程不需要多线程的锁机制，因为都是在同一个线程中运行，所以没有同时访问数据的问题，执行效率比多线程高很多

生成器函数
	yield
	yield from
    	等价于 JS中的yield*
    	
next()    	
	send(None)
	throw(exc_type[, exc_value[, traceback]])
	close()
'''
```



```python
def func():
    for i in range(10):
        yield i

print(list(func()))


# 等价于
def func():
    yield from range(10)

print(list(func()))
```





```python

def consumer():
    r = ''
    while True:
        n = yield r
        if not n:
            return
        print('[CONSUMER] Consuming %s...' % n)
        r = '200 OK'

def produce(c):
    c.send(None)
    n = 0
    while n < 5:
        n = n + 1
        print('[PRODUCER] Producing %s...' % n)
        r = c.send(n)
        print('[PRODUCER] Consumer return: %s' % r)
    c.close()

c = consumer()
produce(c)

'''
执行结果：
[PRODUCER] Producing 1...
[CONSUMER] Consuming 1...
[PRODUCER] Consumer return: 200 OK
[PRODUCER] Producing 2...
[CONSUMER] Consuming 2...
[PRODUCER] Consumer return: 200 OK
[PRODUCER] Producing 3...
[CONSUMER] Consuming 3...
[PRODUCER] Consumer return: 200 OK
[PRODUCER] Producing 4...
[CONSUMER] Consuming 4...
[PRODUCER] Consumer return: 200 OK
[PRODUCER] Producing 5...
[CONSUMER] Consuming 5...
[PRODUCER] Consumer return: 200 OK
'''



'''
注意到consumer函数是一个generator，把一个consumer传入produce后：

首先调用c.send(None)启动生成器；

然后，一旦生产了东西，通过c.send(n)切换到consumer执行；

consumer通过yield拿到消息，处理，又通过yield把结果传回；

produce拿到consumer处理的结果，继续生产下一条消息；

produce决定不生产了，通过c.close()关闭consumer，整个过程结束。

整个流程无锁，由一个线程执行，produce和consumer协作完成任务，所以称为“协程”，而非线程的抢占式多任务。
'''
```





## asyncio

```python
'''
@asyncio.coroutine：asyncio模块中的装饰器，用于将一个生成器声明为协程。
yield from 其实就是等待另外一个协程的返回。

使用async代替@asyncio.coroutine，使用await代替yield from
'''

import asyncio


async def job(t):                   # async 形式的功能
    print('Start job ', t)
    await asyncio.sleep(t)          # 等待 "t" 秒, 期间切换其他任务
    print('Job ', t, ' takes ', t, ' s')


async def main(loop):                       # async 形式的功能
    tasks = [
    loop.create_task(job(t)) for t in range(1, 3)
    ]                                       # 创建任务, 但是不执行
    await asyncio.wait(tasks)               # 执行并等待所有任务完成

t1 = time.time()
loop = asyncio.get_event_loop()             # 建立 loop
loop.run_until_complete(main(loop))         # 执行 loop
loop.close()                                # 关闭 loop
print("Async total time : ", time.time() - t1)



```











## async、await

```python
# https://zhuanlan.zhihu.com/p/95685688


'''
很少情况下会在 async def 的代码块中使用 yield ，如果用了，会产生一个异步的生成器。
任何 async def 内都不能使用 yield from，会抛出语法错误。


'''

#!/usr/bin/env python3
# countasync.py

import asyncio

async def count() :
    print("One") 
    # 交出执行权限1s
    await asyncio.sleep(1) 
    print("Two") 

async def main() :
    # 同时启动
    await asyncio.gather(count() , count() , count()) 

if __name__ == "__main__":
    import time
    s = time.perf_counter() 
    asyncio.run(main()) 
    elapsed = time.perf_counter()  - s
    print(f"{__file__} executed in {elapsed:0.2f} seconds.")
    
    
# =====================================================
import aiohttp
import asyncio

async def job(session):
    response = await session.get(URL)       # 等待并切换
    return str(response.url)


async def main(loop):
    async with aiohttp.ClientSession() as session:      # 官网推荐建立 Session 的形式
        tasks = [loop.create_task(job(session)) for _ in range(2)]
        finished, unfinished = await asyncio.wait(tasks)
        all_results = [r.result() for r in finished]    # 获取所有结果
        print(all_results)

t1 = time.time()
loop = asyncio.get_event_loop()
loop.run_until_complete(main(loop))
loop.close()
print("Async total time:", time.time() - t1)

"""
['https://mofanpy.com/', 'https://mofanpy.com/']
Async total time: 0.11447715759277344
```







```python
#!/usr/bin/env python3
# chained.py

import asyncio
import random
import time

async def part1(n: int)  -> str:
    i = random.randint(0, 10) 
    print(f"part1({n})  sleeping for {i} seconds.") 
    await asyncio.sleep(i) 
    result = f"result{n}-1"
    print(f"Returning part1({n})  == {result}.") 
    return result

async def part2(n: int, arg: str)  -> str:
    i = random.randint(0, 10) 
    print(f"part2{n, arg} sleeping for {i} seconds.") 
    await asyncio.sleep(i) 
    result = f"result{n}-2 derived from {arg}"
    print(f"Returning part2{n, arg} == {result}.") 
    return result

async def chain(n: int)  -> None:
    start = time.perf_counter() 
    p1 = await part1(n) 
    p2 = await part2(n, p1) 
    end = time.perf_counter()  - start
    print(f"-->Chained result{n} => {p2} (took {end:0.2f} seconds) .") 

async def main(*args) :
    await asyncio.gather(*(chain(n)  for n in args)) 

if __name__ == "__main__":
    import sys
    random.seed(444) 
    args = [1, 2, 3] if len(sys.argv)  == 1 else map(int, sys.argv[1:]) 
    start = time.perf_counter() 
    asyncio.run(main(*args)) 
    end = time.perf_counter()  - start
    print(f"Program finished in {end:0.2f} seconds.")
```



## 完整的异步 http 请求

### aiohttp、aiofiles

